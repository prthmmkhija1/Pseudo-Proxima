"""Step 5.1: Multi-Backend Comparison - Compare quantum circuit execution across backends.

Implements the comparison workflow:
1. User specifies backends to compare
2. Validate circuit on all backends
3. Plan parallel execution (if resources allow)
4. Execute on each backend with same parameters
5. Collect and normalize results
6. Calculate comparison metrics
7. Generate comparison report

Parallel Execution Strategy:
    IF sum(memory_requirements) < available_memory * 0.8:
        Execute in parallel using asyncio.gather()
    ELSE:
        Execute sequentially with cleanup between

Comparison Metrics:
| Metric            | Description                 |
| Execution Time    | Wall-clock time per backend |
| Memory Peak       | Maximum memory usage        |
| Result Agreement  | Percentage similarity       |
| Fidelity          | For statevector comparisons |
| Performance Ratio | Time ratio between backends |
"""

from __future__ import annotations

import asyncio
import gc
import time
from collections.abc import Callable
from dataclasses import dataclass, field
from enum import Enum, auto
from typing import TYPE_CHECKING, Any

import numpy as np

if TYPE_CHECKING:
    from proxima.backends.base import BaseBackendAdapter


class ComparisonStatus(Enum):
    """Status of a comparison operation."""

    PENDING = auto()
    VALIDATING = auto()
    PLANNING = auto()
    EXECUTING = auto()
    ANALYZING = auto()
    COMPLETED = auto()
    FAILED = auto()
    PARTIAL = auto()  # Some backends succeeded, some failed


class ExecutionStrategy(Enum):
    """Strategy for executing on multiple backends."""

    PARALLEL = "parallel"  # Execute all at once using asyncio
    SEQUENTIAL = "sequential"  # Execute one after another
    ADAPTIVE = "adaptive"  # Decide based on memory requirements


@dataclass
class BackendResult:
    """Result from a single backend execution."""

    backend_name: str
    success: bool
    execution_time_ms: float
    memory_peak_mb: float
    result: Any | None = None  # ExecutionResult if successful
    error: str | None = None
    probabilities: dict[str, float] = field(default_factory=dict)
    metadata: dict[str, Any] = field(default_factory=dict)


@dataclass
class ComparisonMetrics:
    """Metrics comparing results across backends."""

    # Execution Time metrics
    execution_times: dict[str, float] = field(
        default_factory=dict
    )  # backend -> time_ms
    fastest_backend: str | None = None
    slowest_backend: str | None = None
    time_ratios: dict[str, float] = field(
        default_factory=dict
    )  # backend -> ratio to fastest

    # Memory metrics
    memory_peaks: dict[str, float] = field(default_factory=dict)  # backend -> memory_mb
    lowest_memory_backend: str | None = None

    # Result Agreement metrics
    result_agreement: float = 0.0  # 0.0 to 1.0, percentage of states that match
    pairwise_agreements: dict[str, dict[str, float]] = field(default_factory=dict)

    # Fidelity metrics (for statevector comparisons)
    fidelities: dict[str, dict[str, float]] = field(
        default_factory=dict
    )  # backend_a -> backend_b -> fidelity
    average_fidelity: float = 0.0

    # Performance summary
    recommended_backend: str | None = None
    recommendation_reason: str | None = None

    def to_dict(self) -> dict:
        """Convert metrics to dictionary."""
        return {
            "execution_times": self.execution_times,
            "fastest_backend": self.fastest_backend,
            "slowest_backend": self.slowest_backend,
            "time_ratios": self.time_ratios,
            "memory_peaks": self.memory_peaks,
            "lowest_memory_backend": self.lowest_memory_backend,
            "result_agreement": self.result_agreement,
            "pairwise_agreements": self.pairwise_agreements,
            "fidelities": self.fidelities,
            "average_fidelity": self.average_fidelity,
            "recommended_backend": self.recommended_backend,
            "recommendation_reason": self.recommendation_reason,
        }


@dataclass
class ComparisonReport:
    """Complete comparison report."""

    circuit_info: dict[str, Any]
    backends_compared: list[str]
    execution_strategy: ExecutionStrategy
    total_time_ms: float
    status: ComparisonStatus
    backend_results: dict[str, BackendResult]
    metrics: ComparisonMetrics
    errors: list[str] = field(default_factory=list)
    warnings: list[str] = field(default_factory=list)
    timestamp: float = field(default_factory=time.time)

    def to_dict(self) -> dict:
        """Convert report to dictionary."""
        return {
            "circuit_info": self.circuit_info,
            "backends_compared": self.backends_compared,
            "execution_strategy": self.execution_strategy.value,
            "total_time_ms": self.total_time_ms,
            "status": self.status.name,
            "backend_results": {
                name: {
                    "success": r.success,
                    "execution_time_ms": r.execution_time_ms,
                    "memory_peak_mb": r.memory_peak_mb,
                    "error": r.error,
                    "probabilities": r.probabilities,
                }
                for name, r in self.backend_results.items()
            },
            "metrics": self.metrics.to_dict(),
            "errors": self.errors,
            "warnings": self.warnings,
            "timestamp": self.timestamp,
        }

    def summary(self) -> str:
        """Generate human-readable summary."""
        lines = [
            "=" * 60,
            "MULTI-BACKEND COMPARISON REPORT",
            "=" * 60,
            f"Status: {self.status.name}",
            f"Backends: {', '.join(self.backends_compared)}",
            f"Strategy: {self.execution_strategy.value}",
            f"Total Time: {self.total_time_ms:.2f} ms",
            "",
            "EXECUTION TIMES:",
        ]
        for backend, time_ms in self.metrics.execution_times.items():
            ratio = self.metrics.time_ratios.get(backend, 1.0)
            lines.append(f"  {backend}: {time_ms:.2f} ms ({ratio:.2f}x)")

        lines.extend(
            [
                "",
                f"Fastest: {self.metrics.fastest_backend}",
                f"Result Agreement: {self.metrics.result_agreement * 100:.1f}%",
            ]
        )

        if self.metrics.recommended_backend:
            lines.extend(
                [
                    "",
                    f"Recommended: {self.metrics.recommended_backend}",
                    f"Reason: {self.metrics.recommendation_reason}",
                ]
            )

        if self.errors:
            lines.extend(["", "ERRORS:"] + [f"  - {e}" for e in self.errors])

        if self.warnings:
            lines.extend(["", "WARNINGS:"] + [f"  - {w}" for w in self.warnings])

        lines.append("=" * 60)
        return "\n".join(lines)


class ExecutionPlanner:
    """Plans execution strategy based on resource requirements."""

    def __init__(self, memory_threshold: float = 0.8) -> None:
        """Initialize planner.

        Args:
            memory_threshold: Fraction of available memory to use (default 0.8 = 80%)
        """
        self.memory_threshold = memory_threshold

    def get_available_memory_mb(self) -> float:
        """Get available system memory in MB."""
        try:
            import psutil

            mem = psutil.virtual_memory()
            return mem.available / (1024 * 1024)
        except ImportError:
            # Fallback: assume 4GB available
            return 4096.0

    def plan_execution(
        self,
        memory_requirements: dict[str, float],  # backend -> estimated_mb
    ) -> tuple[ExecutionStrategy, list[list[str]]]:
        """Plan execution strategy based on memory requirements.

        Args:
            memory_requirements: Dict mapping backend name to estimated memory in MB

        Returns:
            Tuple of (strategy, execution_batches)
            - strategy: PARALLEL or SEQUENTIAL
            - execution_batches: List of backend groups to execute together
        """
        available = self.get_available_memory_mb()
        threshold = available * self.memory_threshold

        total_required = sum(memory_requirements.values())

        # Strategy per spec: parallel if total < 80% available
        if total_required < threshold:
            return ExecutionStrategy.PARALLEL, [list(memory_requirements.keys())]

        # Sequential execution with cleanup between
        # Sort by memory requirement (smallest first for better batching)
        sorted_backends = sorted(memory_requirements.items(), key=lambda x: x[1])

        batches: list[list[str]] = []
        current_batch: list[str] = []
        current_memory = 0.0

        for backend, mem_req in sorted_backends:
            if current_memory + mem_req <= threshold and current_batch:
                current_batch.append(backend)
                current_memory += mem_req
            else:
                if current_batch:
                    batches.append(current_batch)
                current_batch = [backend]
                current_memory = mem_req

        if current_batch:
            batches.append(current_batch)

        return ExecutionStrategy.SEQUENTIAL, batches


class ResultAnalyzer:
    """Analyzes and compares results from multiple backends."""

    def __init__(self, tolerance: float = 1e-6) -> None:
        """Initialize analyzer.

        Args:
            tolerance: Tolerance for probability comparison
        """
        self.tolerance = tolerance

    def calculate_agreement(
        self,
        probs_a: dict[str, float],
        probs_b: dict[str, float],
    ) -> float:
        """Calculate agreement percentage between two probability distributions.

        Returns a value between 0.0 and 1.0 representing how similar the distributions are.
        """
        all_keys = set(probs_a.keys()) | set(probs_b.keys())
        if not all_keys:
            return 1.0  # Both empty = perfect agreement

        total_diff = 0.0
        for key in all_keys:
            pa = probs_a.get(key, 0.0)
            pb = probs_b.get(key, 0.0)
            total_diff += abs(pa - pb)

        # Total difference can be at most 2.0 (all mass shifted)
        # Convert to similarity: 1.0 - (diff / 2.0)
        agreement = 1.0 - (total_diff / 2.0)
        return max(0.0, min(1.0, agreement))

    def calculate_fidelity(
        self,
        statevector_a: np.ndarray,
        statevector_b: np.ndarray,
    ) -> float:
        """Calculate fidelity between two statevectors.

        F = |<psi_a|psi_b>|^2
        """
        inner_product = np.vdot(statevector_a, statevector_b)
        fidelity = float(np.abs(inner_product) ** 2)
        return fidelity

    def analyze(
        self,
        backend_results: dict[str, BackendResult],
    ) -> ComparisonMetrics:
        """Analyze results from multiple backends and compute metrics."""
        metrics = ComparisonMetrics()

        successful_backends = {
            name: result for name, result in backend_results.items() if result.success
        }

        if not successful_backends:
            return metrics

        # Execution time metrics
        metrics.execution_times = {
            name: result.execution_time_ms
            for name, result in successful_backends.items()
        }

        if metrics.execution_times:
            metrics.fastest_backend = min(
                metrics.execution_times, key=lambda x: metrics.execution_times[x]
            )
            metrics.slowest_backend = max(
                metrics.execution_times, key=lambda x: metrics.execution_times[x]
            )

            fastest_time = metrics.execution_times[metrics.fastest_backend]
            if fastest_time > 0:
                metrics.time_ratios = {
                    name: time / fastest_time
                    for name, time in metrics.execution_times.items()
                }

        # Memory metrics
        metrics.memory_peaks = {
            name: result.memory_peak_mb for name, result in successful_backends.items()
        }

        if metrics.memory_peaks:
            metrics.lowest_memory_backend = min(
                metrics.memory_peaks, key=lambda x: metrics.memory_peaks[x]
            )

        # Result agreement (pairwise)
        backend_names = list(successful_backends.keys())
        agreements: list[float] = []

        for i, name_a in enumerate(backend_names):
            metrics.pairwise_agreements[name_a] = {}
            for j, name_b in enumerate(backend_names):
                if i == j:
                    metrics.pairwise_agreements[name_a][name_b] = 1.0
                elif i < j:
                    probs_a = successful_backends[name_a].probabilities
                    probs_b = successful_backends[name_b].probabilities
                    agreement = self.calculate_agreement(probs_a, probs_b)
                    metrics.pairwise_agreements[name_a][name_b] = agreement
                    agreements.append(agreement)
                else:
                    # Symmetric
                    metrics.pairwise_agreements[name_a][name_b] = (
                        metrics.pairwise_agreements[name_b][name_a]
                    )

        if agreements:
            metrics.result_agreement = sum(agreements) / len(agreements)
        else:
            metrics.result_agreement = 1.0

        # Fidelity (if statevectors available)
        statevectors: dict[str, np.ndarray] = {}
        for name, result in successful_backends.items():
            if result.result and hasattr(result.result, "data"):
                sv = result.result.data.get("statevector")
                if sv is not None:
                    statevectors[name] = np.asarray(sv, dtype=complex)

        if len(statevectors) >= 2:
            fidelities: list[float] = []
            sv_names = list(statevectors.keys())
            for i, name_a in enumerate(sv_names):
                metrics.fidelities[name_a] = {}
                for j, name_b in enumerate(sv_names):
                    if i == j:
                        metrics.fidelities[name_a][name_b] = 1.0
                    elif i < j:
                        fid = self.calculate_fidelity(
                            statevectors[name_a], statevectors[name_b]
                        )
                        metrics.fidelities[name_a][name_b] = fid
                        fidelities.append(fid)
                    else:
                        metrics.fidelities[name_a][name_b] = metrics.fidelities[name_b][
                            name_a
                        ]

            if fidelities:
                metrics.average_fidelity = sum(fidelities) / len(fidelities)

        # Generate recommendation
        self._generate_recommendation(metrics)

        return metrics

    def _generate_recommendation(self, metrics: ComparisonMetrics) -> None:
        """Generate backend recommendation based on metrics."""
        if not metrics.execution_times:
            return

        # Score each backend: lower time + good agreement = better
        scores: dict[str, float] = {}

        for backend in metrics.execution_times:
            # Normalize time score (lower is better)
            time_score = metrics.time_ratios.get(backend, 1.0)

            # Agreement score (higher is better)
            agreement_scores = [
                v
                for v in metrics.pairwise_agreements.get(backend, {}).values()
                if v < 1.0  # Exclude self-comparison
            ]
            avg_agreement = (
                sum(agreement_scores) / len(agreement_scores)
                if agreement_scores
                else 1.0
            )

            # Combined score: time ratio penalty + agreement bonus
            # Lower score = better
            scores[backend] = time_score - avg_agreement

        if scores:
            metrics.recommended_backend = min(scores, key=lambda x: scores[x])

            # Generate reason
            reasons = []
            if metrics.recommended_backend == metrics.fastest_backend:
                reasons.append("fastest execution")
            if metrics.recommended_backend == metrics.lowest_memory_backend:
                reasons.append("lowest memory usage")

            backend_agreement = metrics.pairwise_agreements.get(
                metrics.recommended_backend, {}
            )
            avg_agree = sum(v for v in backend_agreement.values() if v < 1.0)
            if avg_agree > 0.95:
                reasons.append("high result agreement")

            if reasons:
                metrics.recommendation_reason = ", ".join(reasons)
            else:
                metrics.recommendation_reason = "best overall performance"


class MultiBackendComparator:
    """Main class for comparing quantum circuit execution across multiple backends.

    Implements the Step 5.1 comparison workflow:
    1. User specifies backends to compare
    2. Validate circuit on all backends
    3. Plan parallel execution (if resources allow)
    4. Execute on each backend with same parameters
    5. Collect and normalize results
    6. Calculate comparison metrics
    7. Generate comparison report
    """

    def __init__(
        self,
        planner: ExecutionPlanner | None = None,
        analyzer: ResultAnalyzer | None = None,
        progress_callback: Callable[[str, float], None] | None = None,
    ) -> None:
        """Initialize comparator.

        Args:
            planner: Execution planner (default: create new)
            analyzer: Result analyzer (default: create new)
            progress_callback: Optional callback(stage, progress) for progress updates
        """
        self.planner = planner or ExecutionPlanner()
        self.analyzer = analyzer or ResultAnalyzer()
        self.progress_callback = progress_callback

    def _report_progress(self, stage: str, progress: float) -> None:
        """Report progress if callback is set."""
        if self.progress_callback:
            self.progress_callback(stage, progress)

    async def _execute_backend(
        self,
        adapter: BaseBackendAdapter,
        circuit: Any,
        options: dict[str, Any] | None,
    ) -> BackendResult:
        """Execute circuit on a single backend and capture metrics."""
        backend_name = adapter.get_name()
        start_time = time.perf_counter()

        try:
            import psutil

            process = psutil.Process()
            mem_before = process.memory_info().rss / (1024 * 1024)
        except ImportError:
            mem_before = 0.0

        try:
            # Execute (adapters may be sync or async)
            if asyncio.iscoroutinefunction(adapter.execute):
                result = await adapter.execute(circuit, options)
            else:
                # Run sync adapter in executor to not block
                loop = asyncio.get_event_loop()
                result = await loop.run_in_executor(
                    None, adapter.execute, circuit, options
                )

            execution_time = (time.perf_counter() - start_time) * 1000

            try:
                mem_after = process.memory_info().rss / (1024 * 1024)
                memory_peak = max(0, mem_after - mem_before)
            except Exception:
                memory_peak = 0.0

            # Extract probabilities from result
            probabilities = {}
            if hasattr(result, "data") and isinstance(result.data, dict):
                probabilities = result.data.get("probabilities", {})
                if not probabilities and "counts" in result.data:
                    # Normalize counts to probabilities
                    counts = result.data["counts"]
                    total = sum(counts.values())
                    if total > 0:
                        probabilities = {k: v / total for k, v in counts.items()}

            return BackendResult(
                backend_name=backend_name,
                success=True,
                execution_time_ms=execution_time,
                memory_peak_mb=memory_peak,
                result=result,
                probabilities=probabilities,
                metadata=result.metadata if hasattr(result, "metadata") else {},
            )

        except Exception as e:
            execution_time = (time.perf_counter() - start_time) * 1000
            return BackendResult(
                backend_name=backend_name,
                success=False,
                execution_time_ms=execution_time,
                memory_peak_mb=0.0,
                error=str(e),
            )

    async def _execute_with_semaphore(
        self,
        semaphore: asyncio.Semaphore,
        adapter: BaseBackendAdapter,
        circuit: Any,
        options: dict[str, Any] | None,
        timeout: float | None = None,
    ) -> BackendResult:
        """Execute a backend with semaphore control and optional timeout.
        
        Args:
            semaphore: Semaphore for concurrency control
            adapter: Backend adapter to execute
            circuit: Quantum circuit
            options: Execution options
            timeout: Optional timeout in seconds
            
        Returns:
            BackendResult with execution outcome
        """
        async with semaphore:
            if timeout is not None:
                try:
                    return await asyncio.wait_for(
                        self._execute_backend(adapter, circuit, options),
                        timeout=timeout,
                    )
                except asyncio.TimeoutError:
                    return BackendResult(
                        backend_name=adapter.get_name(),
                        success=False,
                        execution_time_ms=timeout * 1000,
                        memory_peak_mb=0.0,
                        error=f"Execution timed out after {timeout}s",
                    )
            else:
                return await self._execute_backend(adapter, circuit, options)

    async def _execute_batch_parallel(
        self,
        adapters: list[BaseBackendAdapter],
        circuit: Any,
        options: dict[str, Any] | None,
        max_concurrent: int | None = None,
        timeout_per_backend: float | None = None,
        cancellation_event: asyncio.Event | None = None,
    ) -> list[BackendResult]:
        """Execute circuit on multiple backends in parallel with resource management.
        
        Enhanced parallel execution with:
        - Configurable concurrency limits via semaphore
        - Per-backend timeout handling
        - Cancellation support for graceful shutdown
        - Ordered result preservation
        - Automatic resource throttling based on system memory
        
        Args:
            adapters: List of backend adapters to execute
            circuit: Quantum circuit to run
            options: Execution options
            max_concurrent: Maximum concurrent executions (default: auto-detect)
            timeout_per_backend: Timeout per backend in seconds (default: None)
            cancellation_event: Event to signal cancellation (default: None)
            
        Returns:
            List of BackendResult in same order as adapters
        """
        if not adapters:
            return []
            
        # Auto-detect concurrency limit based on available memory
        if max_concurrent is None:
            try:
                import psutil
                available_memory_gb = psutil.virtual_memory().available / (1024**3)
                # Estimate ~2GB per backend execution, cap at number of adapters
                max_concurrent = max(1, min(len(adapters), int(available_memory_gb / 2)))
            except ImportError:
                # Default to min of 4 or number of adapters
                max_concurrent = min(4, len(adapters))
        
        semaphore = asyncio.Semaphore(max_concurrent)
        
        # Create tasks with semaphore control
        async def execute_with_check(
            adapter: BaseBackendAdapter,
        ) -> BackendResult:
            # Check for cancellation before starting
            if cancellation_event and cancellation_event.is_set():
                return BackendResult(
                    backend_name=adapter.get_name(),
                    success=False,
                    execution_time_ms=0.0,
                    memory_peak_mb=0.0,
                    error="Execution cancelled",
                )
            return await self._execute_with_semaphore(
                semaphore, adapter, circuit, options, timeout_per_backend
            )
        
        tasks = [execute_with_check(adapter) for adapter in adapters]
        
        # Use gather with return_exceptions to handle individual failures
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Convert exceptions to BackendResult
        processed_results: list[BackendResult] = []
        for idx, result in enumerate(results):
            if isinstance(result, Exception):
                processed_results.append(
                    BackendResult(
                        backend_name=adapters[idx].get_name(),
                        success=False,
                        execution_time_ms=0.0,
                        memory_peak_mb=0.0,
                        error=f"Unexpected error: {result}",
                    )
                )
            else:
                processed_results.append(result)
        
        return processed_results

    async def _execute_batch_sequential(
        self,
        adapters: list[BaseBackendAdapter],
        circuit: Any,
        options: dict[str, Any] | None,
        timeout_per_backend: float | None = None,
        cancellation_event: asyncio.Event | None = None,
        cleanup_between: bool = True,
    ) -> list[BackendResult]:
        """Execute circuit on backends sequentially with cleanup between.
        
        Enhanced sequential execution with:
        - Per-backend timeout handling
        - Cancellation support for graceful shutdown
        - Configurable cleanup between executions
        - Memory pressure monitoring
        
        Args:
            adapters: List of backend adapters to execute
            circuit: Quantum circuit to run
            options: Execution options
            timeout_per_backend: Timeout per backend in seconds (default: None)
            cancellation_event: Event to signal cancellation (default: None)
            cleanup_between: Whether to run gc.collect() between executions
            
        Returns:
            List of BackendResult in same order as adapters
        """
        results: list[BackendResult] = []
        
        for adapter in adapters:
            # Check for cancellation
            if cancellation_event and cancellation_event.is_set():
                results.append(
                    BackendResult(
                        backend_name=adapter.get_name(),
                        success=False,
                        execution_time_ms=0.0,
                        memory_peak_mb=0.0,
                        error="Execution cancelled",
                    )
                )
                continue
            
            # Execute with optional timeout
            if timeout_per_backend is not None:
                try:
                    result = await asyncio.wait_for(
                        self._execute_backend(adapter, circuit, options),
                        timeout=timeout_per_backend,
                    )
                except asyncio.TimeoutError:
                    result = BackendResult(
                        backend_name=adapter.get_name(),
                        success=False,
                        execution_time_ms=timeout_per_backend * 1000,
                        memory_peak_mb=0.0,
                        error=f"Execution timed out after {timeout_per_backend}s",
                    )
            else:
                result = await self._execute_backend(adapter, circuit, options)
            
            results.append(result)
            
            # Cleanup between executions to manage memory
            if cleanup_between:
                gc.collect()
                # Check memory pressure and wait if needed
                try:
                    import psutil
                    memory_percent = psutil.virtual_memory().percent
                    if memory_percent > 90:
                        # High memory pressure - force aggressive cleanup
                        gc.collect()
                        await asyncio.sleep(0.1)  # Brief pause for memory reclaim
                except ImportError:
                    pass
        
        return results

    def validate_backends(
        self,
        adapters: list[BaseBackendAdapter],
        circuit: Any,
    ) -> tuple[list[BaseBackendAdapter], list[str]]:
        """Validate circuit on all backends.

        Returns:
            Tuple of (valid_adapters, validation_errors)
        """
        valid_adapters = []
        errors = []

        for adapter in adapters:
            try:
                validation = adapter.validate_circuit(circuit)
                if validation.valid:
                    valid_adapters.append(adapter)
                else:
                    errors.append(f"{adapter.get_name()}: {validation.message}")
            except Exception as e:
                errors.append(f"{adapter.get_name()}: validation failed - {e}")

        return valid_adapters, errors

    def estimate_resources(
        self,
        adapters: list[BaseBackendAdapter],
        circuit: Any,
    ) -> dict[str, float]:
        """Estimate memory requirements for each backend.

        Returns:
            Dict mapping backend name to estimated memory in MB
        """
        estimates = {}
        for adapter in adapters:
            try:
                estimate = adapter.estimate_resources(circuit)
                estimates[adapter.get_name()] = estimate.memory_mb or 100.0
            except Exception:
                estimates[adapter.get_name()] = 100.0  # Default estimate
        return estimates

    async def compare(
        self,
        adapters: list[BaseBackendAdapter],
        circuit: Any,
        options: dict[str, Any] | None = None,
        strategy: ExecutionStrategy = ExecutionStrategy.ADAPTIVE,
        max_concurrent: int | None = None,
        timeout_per_backend: float | None = None,
        cancellation_event: asyncio.Event | None = None,
    ) -> ComparisonReport:
        """Compare circuit execution across multiple backends.

        This implements the full Step 5.1 workflow:
        1. Validate circuit on all backends
        2. Plan execution strategy
        3. Execute on each backend with resource management
        4. Analyze and compare results
        5. Generate report

        Args:
            adapters: List of backend adapters to compare
            circuit: Quantum circuit to execute
            options: Execution options (shots, etc.)
            strategy: Execution strategy (PARALLEL, SEQUENTIAL, or ADAPTIVE)
            max_concurrent: Maximum concurrent backend executions (default: auto-detect)
            timeout_per_backend: Timeout per backend in seconds (default: None - no timeout)
            cancellation_event: Event to signal cancellation for graceful shutdown

        Returns:
            ComparisonReport with full comparison results
        """
        start_time = time.perf_counter()
        errors: list[str] = []
        warnings: list[str] = []

        # Check for early cancellation
        if cancellation_event and cancellation_event.is_set():
            return ComparisonReport(
                circuit_info={"type": type(circuit).__name__},
                backends_compared=[a.get_name() for a in adapters],
                execution_strategy=strategy,
                total_time_ms=0.0,
                status=ComparisonStatus.FAILED,
                backend_results={},
                metrics=ComparisonMetrics(),
                errors=["Comparison cancelled before execution"],
            )

        # Extract circuit info
        circuit_info = {
            "type": type(circuit).__name__,
        }
        if hasattr(circuit, "num_qubits"):
            circuit_info["num_qubits"] = circuit.num_qubits
        if hasattr(circuit, "depth"):
            circuit_info["depth"] = circuit.depth()

        self._report_progress("validating", 0.1)

        # Step 2: Validate circuit on all backends
        valid_adapters, validation_errors = self.validate_backends(adapters, circuit)
        errors.extend(validation_errors)

        if not valid_adapters:
            return ComparisonReport(
                circuit_info=circuit_info,
                backends_compared=[a.get_name() for a in adapters],
                execution_strategy=strategy,
                total_time_ms=(time.perf_counter() - start_time) * 1000,
                status=ComparisonStatus.FAILED,
                backend_results={},
                metrics=ComparisonMetrics(),
                errors=errors,
            )

        self._report_progress("planning", 0.2)

        # Step 3: Plan execution strategy
        if strategy == ExecutionStrategy.ADAPTIVE:
            memory_estimates = self.estimate_resources(valid_adapters, circuit)
            actual_strategy, batches = self.planner.plan_execution(memory_estimates)
        elif strategy == ExecutionStrategy.PARALLEL:
            actual_strategy = ExecutionStrategy.PARALLEL
            batches = [[a.get_name() for a in valid_adapters]]
        else:
            actual_strategy = ExecutionStrategy.SEQUENTIAL
            batches = [[a.get_name()] for a in valid_adapters]

        # Map adapter names to adapters
        adapter_map = {a.get_name(): a for a in valid_adapters}

        self._report_progress("executing", 0.3)

        # Step 4: Execute on each backend with enhanced resource management
        all_results: list[BackendResult] = []

        for batch_idx, batch in enumerate(batches):
            # Check for cancellation between batches
            if cancellation_event and cancellation_event.is_set():
                warnings.append(f"Cancelled after {batch_idx} of {len(batches)} batches")
                break
                
            batch_adapters = [
                adapter_map[name] for name in batch if name in adapter_map
            ]

            if actual_strategy == ExecutionStrategy.PARALLEL:
                batch_results = await self._execute_batch_parallel(
                    batch_adapters,
                    circuit,
                    options,
                    max_concurrent=max_concurrent,
                    timeout_per_backend=timeout_per_backend,
                    cancellation_event=cancellation_event,
                )
            else:
                batch_results = await self._execute_batch_sequential(
                    batch_adapters,
                    circuit,
                    options,
                    timeout_per_backend=timeout_per_backend,
                    cancellation_event=cancellation_event,
                )

            all_results.extend(batch_results)

            # Report progress
            progress = 0.3 + 0.5 * ((batch_idx + 1) / len(batches))
            self._report_progress("executing", progress)

        # Build results dict
        backend_results = {r.backend_name: r for r in all_results}

        # Check for partial failures
        successful = sum(1 for r in all_results if r.success)
        failed = sum(1 for r in all_results if not r.success)

        for result in all_results:
            if not result.success:
                errors.append(f"{result.backend_name}: {result.error}")

        self._report_progress("analyzing", 0.85)

        # Step 5 & 6: Analyze and compare results
        metrics = self.analyzer.analyze(backend_results)

        # Determine final status
        if failed == 0:
            status = ComparisonStatus.COMPLETED
        elif successful == 0:
            status = ComparisonStatus.FAILED
        else:
            status = ComparisonStatus.PARTIAL
            warnings.append(f"{failed} of {len(all_results)} backends failed")

        self._report_progress("completed", 1.0)

        # Step 7: Generate report
        total_time = (time.perf_counter() - start_time) * 1000

        return ComparisonReport(
            circuit_info=circuit_info,
            backends_compared=[a.get_name() for a in adapters],
            execution_strategy=actual_strategy,
            total_time_ms=total_time,
            status=status,
            backend_results=backend_results,
            metrics=metrics,
            errors=errors,
            warnings=warnings,
        )

    def compare_sync(
        self,
        adapters: list[BaseBackendAdapter],
        circuit: Any,
        options: dict[str, Any] | None = None,
        strategy: ExecutionStrategy = ExecutionStrategy.ADAPTIVE,
    ) -> ComparisonReport:
        """Synchronous wrapper for compare()."""
        return asyncio.run(self.compare(adapters, circuit, options, strategy))


# Convenience function
def compare_backends(
    adapters: list[BaseBackendAdapter],
    circuit: Any,
    options: dict[str, Any] | None = None,
    strategy: ExecutionStrategy = ExecutionStrategy.ADAPTIVE,
) -> ComparisonReport:
    """Compare quantum circuit execution across multiple backends.

    This is a convenience function that creates a MultiBackendComparator
    and runs a comparison.

    Args:
        adapters: List of backend adapters to compare
        circuit: Quantum circuit to execute
        options: Execution options
        strategy: Execution strategy

    Returns:
        ComparisonReport with comparison results
    """
    comparator = MultiBackendComparator()
    return comparator.compare_sync(adapters, circuit, options, strategy)


# ==============================================================================
# Step 4.2: Backend Comparison Matrix
# ==============================================================================


@dataclass
class BackendCapabilityEntry:
    """Entry in the backend comparison matrix."""

    name: str
    supports_state_vector: bool = True
    supports_density_matrix: bool = False
    supports_gpu: bool = False
    is_cpu_optimized: bool = False
    supports_noise: bool = False
    max_qubits: int = 25
    use_case: str = "General-purpose"
    performance_tier: str = "standard"  # "standard", "high", "very-high"
    memory_efficiency: str = "standard"  # "low", "standard", "high"


class BackendComparisonMatrix:
    """
    Step 4.2: Backend Comparison Matrix for unified backend selection.

    Provides comparison data across all supported backends including:
    - LRET: Custom rank-reduction
    - Cirq: Google's framework
    - Qiskit Aer: IBM's feature-rich simulator
    - QuEST: High-performance C++ with GPU
    - cuQuantum: NVIDIA GPU-accelerated
    - qsim: Google's CPU-optimized simulator

    Comparison Dimensions:
    | Backend   | SV | DM | GPU | CPU Opt | Noise | Max Qubits | Use Case                    |
    |-----------|----|----|-----|---------|-------|------------|-----------------------------|
    | LRET      |   |   |    |        |      | 15         | Custom rank-reduction       |
    | Cirq      |   |   |    |        |      | 20         | General-purpose             |
    | Qiskit Aer|   |   |    |        |      | 30         | Qiskit ecosystem            |
    | QuEST     |   |   |    |        |      | 30         | High-performance research   |
    | cuQuantum |   |   |    |        |      | 35+        | GPU-accelerated large SV    |
    | qsim      |   |   |    |       |      | 35+        | CPU-optimized large SV      |
    """

    # Static comparison matrix
    MATRIX: dict[str, BackendCapabilityEntry] = {
        "lret": BackendCapabilityEntry(
            name="lret",
            supports_state_vector=True,
            supports_density_matrix=True,
            supports_gpu=False,
            is_cpu_optimized=False,
            supports_noise=True,
            max_qubits=15,
            use_case="Custom rank-reduction for noisy circuits",
            performance_tier="standard",
            memory_efficiency="high",  # Rank-reduced representation
        ),
        "cirq": BackendCapabilityEntry(
            name="cirq",
            supports_state_vector=True,
            supports_density_matrix=True,
            supports_gpu=False,
            is_cpu_optimized=False,
            supports_noise=True,
            max_qubits=20,
            use_case="General-purpose simulation",
            performance_tier="standard",
            memory_efficiency="standard",
        ),
        "qiskit": BackendCapabilityEntry(
            name="qiskit",
            supports_state_vector=True,
            supports_density_matrix=True,
            supports_gpu=False,
            is_cpu_optimized=False,
            supports_noise=True,
            max_qubits=30,
            use_case="Qiskit ecosystem integration",
            performance_tier="standard",
            memory_efficiency="standard",
        ),
        "quest": BackendCapabilityEntry(
            name="quest",
            supports_state_vector=True,
            supports_density_matrix=True,
            supports_gpu=True,
            is_cpu_optimized=True,
            supports_noise=True,
            max_qubits=30,
            use_case="High-performance research simulation",
            performance_tier="high",
            memory_efficiency="standard",
        ),
        "cuquantum": BackendCapabilityEntry(
            name="cuquantum",
            supports_state_vector=True,
            supports_density_matrix=False,
            supports_gpu=True,
            is_cpu_optimized=False,
            supports_noise=False,
            max_qubits=35,
            use_case="GPU-accelerated large state vector",
            performance_tier="very-high",
            memory_efficiency="low",  # GPU memory limited
        ),
        "qsim": BackendCapabilityEntry(
            name="qsim",
            supports_state_vector=True,
            supports_density_matrix=False,
            supports_gpu=False,
            is_cpu_optimized=True,
            supports_noise=False,
            max_qubits=35,
            use_case="CPU-optimized large state vector",
            performance_tier="very-high",
            memory_efficiency="standard",
        ),
    }

    @classmethod
    def get_entry(cls, backend_name: str) -> BackendCapabilityEntry | None:
        """Get capability entry for a backend."""
        return cls.MATRIX.get(backend_name.lower())

    @classmethod
    def list_all(cls) -> list[BackendCapabilityEntry]:
        """List all backend entries."""
        return list(cls.MATRIX.values())

    @classmethod
    def get_backends_for_simulation_type(
        cls,
        state_vector: bool = True,
        density_matrix: bool = False,
    ) -> list[str]:
        """Get backends supporting specified simulation type."""
        results = []
        for name, entry in cls.MATRIX.items():
            if state_vector and not entry.supports_state_vector:
                continue
            if density_matrix and not entry.supports_density_matrix:
                continue
            results.append(name)
        return results

    @classmethod
    def get_gpu_backends(cls) -> list[str]:
        """Get backends with GPU support."""
        return [name for name, entry in cls.MATRIX.items() if entry.supports_gpu]

    @classmethod
    def get_cpu_optimized_backends(cls) -> list[str]:
        """Get CPU-optimized backends."""
        return [name for name, entry in cls.MATRIX.items() if entry.is_cpu_optimized]

    @classmethod
    def get_backends_supporting_noise(cls) -> list[str]:
        """Get backends supporting noise simulation."""
        return [name for name, entry in cls.MATRIX.items() if entry.supports_noise]

    @classmethod
    def get_backends_for_qubit_count(cls, qubit_count: int) -> list[str]:
        """Get backends that can handle specified qubit count."""
        return [
            name
            for name, entry in cls.MATRIX.items()
            if entry.max_qubits >= qubit_count
        ]

    @classmethod
    def compare(
        cls,
        backend_a: str,
        backend_b: str,
    ) -> dict[str, dict[str, Any]]:
        """Compare two backends side by side."""
        entry_a = cls.MATRIX.get(backend_a.lower())
        entry_b = cls.MATRIX.get(backend_b.lower())

        if not entry_a or not entry_b:
            return {}

        comparison = {
            "state_vector": {
                backend_a: entry_a.supports_state_vector,
                backend_b: entry_b.supports_state_vector,
            },
            "density_matrix": {
                backend_a: entry_a.supports_density_matrix,
                backend_b: entry_b.supports_density_matrix,
            },
            "gpu_support": {
                backend_a: entry_a.supports_gpu,
                backend_b: entry_b.supports_gpu,
            },
            "cpu_optimized": {
                backend_a: entry_a.is_cpu_optimized,
                backend_b: entry_b.is_cpu_optimized,
            },
            "noise_support": {
                backend_a: entry_a.supports_noise,
                backend_b: entry_b.supports_noise,
            },
            "max_qubits": {
                backend_a: entry_a.max_qubits,
                backend_b: entry_b.max_qubits,
            },
            "use_case": {
                backend_a: entry_a.use_case,
                backend_b: entry_b.use_case,
            },
            "performance_tier": {
                backend_a: entry_a.performance_tier,
                backend_b: entry_b.performance_tier,
            },
        }
        return comparison

    @classmethod
    def get_recommendation(
        cls,
        qubit_count: int,
        needs_density_matrix: bool = False,
        needs_noise: bool = False,
        gpu_available: bool = False,
        prefer_performance: bool = True,
    ) -> tuple[str, str]:
        """Get recommended backend based on requirements.

        Returns:
            Tuple of (backend_name, reason)
        """
        # Filter by requirements
        candidates = []
        for name, entry in cls.MATRIX.items():
            # Check qubit capacity
            if entry.max_qubits < qubit_count:
                continue
            # Check density matrix support
            if needs_density_matrix and not entry.supports_density_matrix:
                continue
            # Check noise support
            if needs_noise and not entry.supports_noise:
                continue
            candidates.append((name, entry))

        if not candidates:
            return ("qiskit", "Fallback - no backend meets all requirements")

        # Score candidates
        scored = []
        for name, entry in candidates:
            score = 0.0

            # Performance scoring
            if entry.performance_tier == "very-high":
                score += 1.0
            elif entry.performance_tier == "high":
                score += 0.7
            else:
                score += 0.4

            # GPU bonus if available
            if gpu_available and entry.supports_gpu:
                score += 0.5
                if qubit_count > 25:
                    score += 0.3  # Extra bonus for large circuits

            # CPU optimization bonus when no GPU
            if not gpu_available and entry.is_cpu_optimized:
                score += 0.3

            # Large circuit handling
            if qubit_count > 25:
                if entry.max_qubits >= 35:
                    score += 0.2

            scored.append((name, entry, score))

        # Sort by score
        scored.sort(key=lambda x: x[2], reverse=True)
        winner_name, winner_entry, winner_score = scored[0]

        # Generate reason
        reasons = []
        if winner_entry.supports_gpu and gpu_available:
            reasons.append("GPU acceleration available")
        if winner_entry.is_cpu_optimized:
            reasons.append("CPU-optimized")
        if winner_entry.performance_tier == "very-high":
            reasons.append("highest performance tier")
        if winner_entry.max_qubits >= qubit_count + 5:
            reasons.append(f"supports up to {winner_entry.max_qubits} qubits")

        reason = (
            f"Best for {qubit_count}-qubit circuit: " + ", ".join(reasons)
            if reasons
            else winner_entry.use_case
        )

        return (winner_name, reason)

    @classmethod
    def to_markdown_table(cls) -> str:
        """Generate markdown table of backend comparison."""
        lines = [
            "| Backend | SV | DM | GPU | CPU Opt | Noise | Max Qubits | Use Case |",
            "|---------|----|----|-----|---------|-------|------------|----------|",
        ]

        for name, entry in cls.MATRIX.items():
            sv = "" if entry.supports_state_vector else ""
            dm = "" if entry.supports_density_matrix else ""
            gpu = "" if entry.supports_gpu else ""
            cpu = "" if entry.is_cpu_optimized else ""
            noise = "" if entry.supports_noise else ""

            lines.append(
                f"| {name:7} | {sv:2} | {dm:2} | {gpu:3} | {cpu:7} | {noise:5} | "
                f"{entry.max_qubits:10} | {entry.use_case} |"
            )

        return "\n".join(lines)


# ==============================================================================
# Step 4.2: Performance Comparison Metrics
# ==============================================================================


@dataclass
class PerformanceMetrics:
    """Performance metrics for backend comparison."""

    backend_name: str
    execution_time_ms: float
    memory_peak_mb: float
    cpu_utilization_percent: float = 0.0
    gpu_utilization_percent: float = 0.0
    parallel_efficiency: float = 1.0  # Ratio of actual speedup to ideal speedup


@dataclass
class AccuracyMetrics:
    """Accuracy metrics for backend comparison."""

    backend_name: str
    state_vector_fidelity: float = 1.0  # 0-1
    measurement_distribution_similarity: float = 1.0  # 0-1
    numerical_stability_score: float = 1.0  # 0-1


class BackendPerformanceTracker:
    """
    Step 4.2: Track and compare backend performance over time.

    Maintains a history of:
    - Execution times per circuit size
    - Memory usage patterns
    - Success rates
    - Accuracy comparisons
    """

    def __init__(self) -> None:
        self._history: dict[str, list[PerformanceMetrics]] = {}
        self._accuracy_history: dict[str, list[AccuracyMetrics]] = {}

    def record_execution(
        self,
        backend_name: str,
        execution_time_ms: float,
        memory_peak_mb: float,
        cpu_utilization: float = 0.0,
        gpu_utilization: float = 0.0,
    ) -> None:
        """Record a backend execution for performance tracking."""
        if backend_name not in self._history:
            self._history[backend_name] = []

        self._history[backend_name].append(
            PerformanceMetrics(
                backend_name=backend_name,
                execution_time_ms=execution_time_ms,
                memory_peak_mb=memory_peak_mb,
                cpu_utilization_percent=cpu_utilization,
                gpu_utilization_percent=gpu_utilization,
            )
        )

    def record_accuracy(
        self,
        backend_name: str,
        fidelity: float,
        distribution_similarity: float = 1.0,
        numerical_stability: float = 1.0,
    ) -> None:
        """Record accuracy metrics for a backend."""
        if backend_name not in self._accuracy_history:
            self._accuracy_history[backend_name] = []

        self._accuracy_history[backend_name].append(
            AccuracyMetrics(
                backend_name=backend_name,
                state_vector_fidelity=fidelity,
                measurement_distribution_similarity=distribution_similarity,
                numerical_stability_score=numerical_stability,
            )
        )

    def get_average_execution_time(self, backend_name: str) -> float:
        """Get average execution time for a backend."""
        history = self._history.get(backend_name, [])
        if not history:
            return 0.0
        return sum(m.execution_time_ms for m in history) / len(history)

    def get_average_memory_usage(self, backend_name: str) -> float:
        """Get average memory usage for a backend."""
        history = self._history.get(backend_name, [])
        if not history:
            return 0.0
        return sum(m.memory_peak_mb for m in history) / len(history)

    def get_success_rate(self, backend_name: str) -> float:
        """Get success rate (placeholder - would track failures in production)."""
        # In production, this would track actual success/failure counts
        return 0.95 if backend_name in self._history else 0.8

    def get_performance_ranking(self) -> list[tuple[str, float]]:
        """Get backends ranked by performance (lower time is better)."""
        rankings = []
        for name in self._history:
            avg_time = self.get_average_execution_time(name)
            if avg_time > 0:
                rankings.append((name, avg_time))
        return sorted(rankings, key=lambda x: x[1])

    def compare_backends(
        self,
        backend_a: str,
        backend_b: str,
    ) -> dict[str, Any]:
        """Compare two backends based on recorded history."""
        time_a = self.get_average_execution_time(backend_a)
        time_b = self.get_average_execution_time(backend_b)
        mem_a = self.get_average_memory_usage(backend_a)
        mem_b = self.get_average_memory_usage(backend_b)

        time_ratio = time_a / time_b if time_b > 0 else 0.0
        mem_ratio = mem_a / mem_b if mem_b > 0 else 0.0

        return {
            "execution_time": {
                backend_a: time_a,
                backend_b: time_b,
                "ratio": time_ratio,
                "faster": backend_a if time_a < time_b else backend_b,
            },
            "memory_usage": {
                backend_a: mem_a,
                backend_b: mem_b,
                "ratio": mem_ratio,
                "more_efficient": backend_a if mem_a < mem_b else backend_b,
            },
        }


# =============================================================================
# Advanced Statistical Analysis (Feature - Comparison Aggregator)
# =============================================================================


@dataclass
class StatisticalSummary:
    """Statistical summary of a dataset."""
    
    count: int
    mean: float
    std: float
    min: float
    max: float
    median: float
    q1: float  # 25th percentile
    q3: float  # 75th percentile
    iqr: float  # Interquartile range
    skewness: float
    kurtosis: float
    confidence_interval_95: tuple[float, float]


@dataclass
class HypothesisTestResult:
    """Result of a statistical hypothesis test."""
    
    test_name: str
    statistic: float
    p_value: float
    significant: bool  # At alpha=0.05
    effect_size: float
    interpretation: str


@dataclass
class CorrelationResult:
    """Result of correlation analysis."""
    
    variable_a: str
    variable_b: str
    correlation: float  # Pearson correlation coefficient
    p_value: float
    strength: str  # 'weak', 'moderate', 'strong'


class AdvancedStatisticalAnalyzer:
    """Advanced statistical analysis for comparison results.
    
    Provides:
    - Descriptive statistics
    - Hypothesis testing (t-test, Mann-Whitney U)
    - Effect size calculations (Cohen's d)
    - Correlation analysis
    - Confidence intervals
    - Outlier detection
    """
    
    def __init__(self, alpha: float = 0.05) -> None:
        """Initialize analyzer with significance level."""
        self.alpha = alpha
    
    def compute_descriptive_stats(self, values: list[float]) -> StatisticalSummary:
        """Compute comprehensive descriptive statistics.
        
        Args:
            values: List of numeric values
            
        Returns:
            StatisticalSummary with all statistics
        """
        if not values:
            return StatisticalSummary(
                count=0, mean=0, std=0, min=0, max=0, median=0,
                q1=0, q3=0, iqr=0, skewness=0, kurtosis=0,
                confidence_interval_95=(0, 0),
            )
        
        arr = np.array(values)
        n = len(arr)
        mean = float(np.mean(arr))
        std = float(np.std(arr, ddof=1)) if n > 1 else 0.0
        
        # Percentiles
        q1 = float(np.percentile(arr, 25))
        median = float(np.median(arr))
        q3 = float(np.percentile(arr, 75))
        iqr = q3 - q1
        
        # Skewness and kurtosis
        skewness = self._compute_skewness(arr, mean, std)
        kurtosis = self._compute_kurtosis(arr, mean, std)
        
        # 95% confidence interval for mean
        if n > 1 and std > 0:
            se = std / np.sqrt(n)
            # Using t-distribution critical value approximation
            t_crit = 1.96 if n > 30 else 2.0  # Simplified
            ci_lower = mean - t_crit * se
            ci_upper = mean + t_crit * se
        else:
            ci_lower = ci_upper = mean
        
        return StatisticalSummary(
            count=n,
            mean=mean,
            std=std,
            min=float(np.min(arr)),
            max=float(np.max(arr)),
            median=median,
            q1=q1,
            q3=q3,
            iqr=iqr,
            skewness=skewness,
            kurtosis=kurtosis,
            confidence_interval_95=(ci_lower, ci_upper),
        )
    
    def _compute_skewness(self, arr: np.ndarray, mean: float, std: float) -> float:
        """Compute skewness coefficient."""
        if std == 0 or len(arr) < 3:
            return 0.0
        n = len(arr)
        m3 = np.mean((arr - mean) ** 3)
        return float(m3 / (std ** 3) * np.sqrt(n * (n - 1)) / (n - 2)) if n > 2 else 0.0
    
    def _compute_kurtosis(self, arr: np.ndarray, mean: float, std: float) -> float:
        """Compute excess kurtosis."""
        if std == 0 or len(arr) < 4:
            return 0.0
        m4 = np.mean((arr - mean) ** 4)
        return float(m4 / (std ** 4) - 3)
    
    def welch_t_test(
        self,
        sample_a: list[float],
        sample_b: list[float],
        alternative: str = "two-sided",
    ) -> HypothesisTestResult:
        """Perform Welch's t-test for comparing two samples.
        
        This is more robust than Student's t-test when variances are unequal.
        
        Args:
            sample_a: First sample
            sample_b: Second sample
            alternative: 'two-sided', 'greater', or 'less'
            
        Returns:
            HypothesisTestResult with test outcome
        """
        if len(sample_a) < 2 or len(sample_b) < 2:
            return HypothesisTestResult(
                test_name="Welch's t-test",
                statistic=0.0,
                p_value=1.0,
                significant=False,
                effect_size=0.0,
                interpretation="Insufficient data for test",
            )
        
        arr_a = np.array(sample_a)
        arr_b = np.array(sample_b)
        
        n_a, n_b = len(arr_a), len(arr_b)
        mean_a, mean_b = np.mean(arr_a), np.mean(arr_b)
        var_a, var_b = np.var(arr_a, ddof=1), np.var(arr_b, ddof=1)
        
        # Welch's t-statistic
        se = np.sqrt(var_a / n_a + var_b / n_b)
        if se == 0:
            return HypothesisTestResult(
                test_name="Welch's t-test",
                statistic=0.0,
                p_value=1.0,
                significant=False,
                effect_size=0.0,
                interpretation="Zero variance in samples",
            )
        
        t_stat = float((mean_a - mean_b) / se)
        
        # Welch-Satterthwaite degrees of freedom
        num = (var_a / n_a + var_b / n_b) ** 2
        denom = (var_a / n_a) ** 2 / (n_a - 1) + (var_b / n_b) ** 2 / (n_b - 1)
        df = num / denom if denom > 0 else 1
        
        # Approximate p-value using normal distribution for large df
        p_value = self._t_distribution_pvalue(t_stat, df, alternative)
        
        # Effect size (Cohen's d)
        pooled_std = np.sqrt(((n_a - 1) * var_a + (n_b - 1) * var_b) / (n_a + n_b - 2))
        cohens_d = float((mean_a - mean_b) / pooled_std) if pooled_std > 0 else 0.0
        
        # Interpretation
        effect_interpretation = self._interpret_effect_size(abs(cohens_d))
        significant = p_value < self.alpha
        
        if significant:
            direction = "greater than" if mean_a > mean_b else "less than"
            interpretation = f"Significant difference (p={p_value:.4f}). Sample A is {direction} Sample B with {effect_interpretation} effect."
        else:
            interpretation = f"No significant difference (p={p_value:.4f}). Effect size is {effect_interpretation}."
        
        return HypothesisTestResult(
            test_name="Welch's t-test",
            statistic=t_stat,
            p_value=p_value,
            significant=significant,
            effect_size=abs(cohens_d),
            interpretation=interpretation,
        )
    
    def _t_distribution_pvalue(self, t_stat: float, df: float, alternative: str) -> float:
        """Approximate p-value from t-distribution."""
        # Using normal approximation for simplicity
        # In production, use scipy.stats.t.sf
        from math import erf, sqrt
        
        # Standard normal CDF approximation
        def norm_cdf(x: float) -> float:
            return 0.5 * (1 + erf(x / sqrt(2)))
        
        if df > 30:
            # Use normal approximation
            if alternative == "two-sided":
                return 2 * (1 - norm_cdf(abs(t_stat)))
            elif alternative == "greater":
                return 1 - norm_cdf(t_stat)
            else:  # less
                return norm_cdf(t_stat)
        else:
            # Rough t-distribution approximation
            # Inflate p-value slightly for small df
            adjustment = 1 + 2 / df
            if alternative == "two-sided":
                return min(1.0, 2 * (1 - norm_cdf(abs(t_stat))) * adjustment)
            elif alternative == "greater":
                return min(1.0, (1 - norm_cdf(t_stat)) * adjustment)
            else:
                return min(1.0, norm_cdf(t_stat) * adjustment)
    
    def _interpret_effect_size(self, d: float) -> str:
        """Interpret Cohen's d effect size."""
        if d < 0.2:
            return "negligible"
        elif d < 0.5:
            return "small"
        elif d < 0.8:
            return "medium"
        else:
            return "large"
    
    def mann_whitney_u_test(
        self,
        sample_a: list[float],
        sample_b: list[float],
    ) -> HypothesisTestResult:
        """Perform Mann-Whitney U test (non-parametric alternative to t-test).
        
        Useful when data is not normally distributed.
        
        Args:
            sample_a: First sample
            sample_b: Second sample
            
        Returns:
            HypothesisTestResult with test outcome
        """
        if len(sample_a) < 3 or len(sample_b) < 3:
            return HypothesisTestResult(
                test_name="Mann-Whitney U",
                statistic=0.0,
                p_value=1.0,
                significant=False,
                effect_size=0.0,
                interpretation="Insufficient data for test",
            )
        
        arr_a = np.array(sample_a)
        arr_b = np.array(sample_b)
        n_a, n_b = len(arr_a), len(arr_b)
        
        # Combine and rank
        combined = np.concatenate([arr_a, arr_b])
        ranks = self._rank_data(combined)
        
        # Calculate U statistics
        r_a = sum(ranks[:n_a])
        u_a = r_a - n_a * (n_a + 1) / 2
        u_b = n_a * n_b - u_a
        u = min(u_a, u_b)
        
        # Normal approximation for large samples
        mean_u = n_a * n_b / 2
        std_u = np.sqrt(n_a * n_b * (n_a + n_b + 1) / 12)
        
        if std_u > 0:
            z = (u - mean_u) / std_u
            from math import erf, sqrt
            p_value = 2 * (1 - 0.5 * (1 + erf(abs(z) / sqrt(2))))
        else:
            p_value = 1.0
            z = 0.0
        
        # Effect size (rank-biserial correlation)
        r = 1 - 2 * u / (n_a * n_b)
        
        significant = p_value < self.alpha
        
        if significant:
            interpretation = f"Significant difference (p={p_value:.4f}). Rank-biserial r={r:.3f}."
        else:
            interpretation = f"No significant difference (p={p_value:.4f})."
        
        return HypothesisTestResult(
            test_name="Mann-Whitney U",
            statistic=float(u),
            p_value=p_value,
            significant=significant,
            effect_size=abs(r),
            interpretation=interpretation,
        )
    
    def _rank_data(self, data: np.ndarray) -> np.ndarray:
        """Rank data with average rank for ties."""
        sorted_indices = np.argsort(data)
        ranks = np.empty_like(sorted_indices, dtype=float)
        ranks[sorted_indices] = np.arange(1, len(data) + 1, dtype=float)
        
        # Handle ties by averaging ranks
        for val in np.unique(data):
            mask = data == val
            if np.sum(mask) > 1:
                ranks[mask] = np.mean(ranks[mask])
        
        return ranks
    
    def correlation_analysis(
        self,
        data_x: list[float],
        data_y: list[float],
        var_name_x: str = "X",
        var_name_y: str = "Y",
    ) -> CorrelationResult:
        """Compute Pearson correlation coefficient.
        
        Args:
            data_x: First variable values
            data_y: Second variable values
            var_name_x: Name of first variable
            var_name_y: Name of second variable
            
        Returns:
            CorrelationResult with correlation statistics
        """
        if len(data_x) != len(data_y) or len(data_x) < 3:
            return CorrelationResult(
                variable_a=var_name_x,
                variable_b=var_name_y,
                correlation=0.0,
                p_value=1.0,
                strength="none",
            )
        
        arr_x = np.array(data_x)
        arr_y = np.array(data_y)
        
        # Pearson correlation
        mean_x, mean_y = np.mean(arr_x), np.mean(arr_y)
        std_x, std_y = np.std(arr_x, ddof=1), np.std(arr_y, ddof=1)
        
        if std_x == 0 or std_y == 0:
            return CorrelationResult(
                variable_a=var_name_x,
                variable_b=var_name_y,
                correlation=0.0,
                p_value=1.0,
                strength="none",
            )
        
        cov = np.mean((arr_x - mean_x) * (arr_y - mean_y))
        r = float(cov / (std_x * std_y))
        
        # P-value approximation using t-distribution
        n = len(arr_x)
        if abs(r) < 1:
            t_stat = r * np.sqrt((n - 2) / (1 - r ** 2))
            p_value = self._t_distribution_pvalue(t_stat, n - 2, "two-sided")
        else:
            p_value = 0.0
        
        # Interpret strength
        abs_r = abs(r)
        if abs_r < 0.3:
            strength = "weak"
        elif abs_r < 0.7:
            strength = "moderate"
        else:
            strength = "strong"
        
        return CorrelationResult(
            variable_a=var_name_x,
            variable_b=var_name_y,
            correlation=r,
            p_value=p_value,
            strength=strength,
        )
    
    def detect_outliers(
        self,
        values: list[float],
        method: str = "iqr",
    ) -> tuple[list[int], list[float]]:
        """Detect outliers in data.
        
        Args:
            values: Data values
            method: Detection method ('iqr' or 'zscore')
            
        Returns:
            Tuple of (outlier_indices, outlier_values)
        """
        if len(values) < 4:
            return [], []
        
        arr = np.array(values)
        outlier_mask = np.zeros(len(arr), dtype=bool)
        
        if method == "iqr":
            q1 = np.percentile(arr, 25)
            q3 = np.percentile(arr, 75)
            iqr = q3 - q1
            lower = q1 - 1.5 * iqr
            upper = q3 + 1.5 * iqr
            outlier_mask = (arr < lower) | (arr > upper)
        elif method == "zscore":
            mean = np.mean(arr)
            std = np.std(arr, ddof=1)
            if std > 0:
                z_scores = np.abs((arr - mean) / std)
                outlier_mask = z_scores > 3
        
        indices = list(np.where(outlier_mask)[0])
        outlier_values = [float(arr[i]) for i in indices]
        
        return indices, outlier_values


# =============================================================================
# Visualization Generation (Feature - Comparison Aggregator)
# =============================================================================


@dataclass
class ComparisonVisualization:
    """Container for comparison visualizations."""
    
    execution_time_chart: str  # SVG or ASCII
    memory_chart: str
    agreement_heatmap: str
    performance_radar: str | None = None
    format: str = "svg"  # 'svg' or 'ascii'


class ComparisonVisualizer:
    """Generate visualizations for backend comparisons.
    
    Supports:
    - Bar charts for execution times
    - Memory usage comparisons
    - Agreement heatmaps
    - Performance radar charts
    - ASCII fallback for terminal output
    """
    
    COLORS = [
        "#3498db", "#2ecc71", "#e74c3c", "#f39c12",
        "#9b59b6", "#1abc9c", "#34495e", "#e67e22",
    ]
    
    def __init__(self, use_ascii: bool = False) -> None:
        """Initialize visualizer.
        
        Args:
            use_ascii: Use ASCII charts instead of SVG
        """
        self.use_ascii = use_ascii
    
    def generate_all(
        self,
        metrics: ComparisonMetrics,
    ) -> ComparisonVisualization:
        """Generate all visualizations for a comparison.
        
        Args:
            metrics: Comparison metrics to visualize
            
        Returns:
            ComparisonVisualization with all charts
        """
        if self.use_ascii:
            return ComparisonVisualization(
                execution_time_chart=self._ascii_bar_chart(
                    metrics.execution_times, "Execution Times (ms)"
                ),
                memory_chart=self._ascii_bar_chart(
                    metrics.memory_peaks, "Memory Usage (MB)"
                ),
                agreement_heatmap=self._ascii_agreement_matrix(
                    metrics.pairwise_agreements
                ),
                format="ascii",
            )
        else:
            return ComparisonVisualization(
                execution_time_chart=self._svg_bar_chart(
                    metrics.execution_times, "Execution Times (ms)"
                ),
                memory_chart=self._svg_bar_chart(
                    metrics.memory_peaks, "Memory Usage (MB)"
                ),
                agreement_heatmap=self._svg_heatmap(
                    metrics.pairwise_agreements, "Result Agreement"
                ),
                performance_radar=self._svg_radar_chart(metrics),
                format="svg",
            )
    
    def _ascii_bar_chart(
        self,
        data: dict[str, float],
        title: str,
        width: int = 40,
    ) -> str:
        """Generate ASCII bar chart."""
        if not data:
            return f"{title}\n  No data available"
        
        lines = [f"  {title}", "  " + "=" * len(title)]
        max_val = max(data.values()) if data.values() else 1
        max_label = max(len(str(k)) for k in data.keys())
        
        for label, value in sorted(data.items(), key=lambda x: -x[1]):
            bar_len = int((value / max_val) * width) if max_val > 0 else 0
            bar = "" * bar_len
            label_str = str(label).ljust(max_label)
            lines.append(f"  {label_str} {bar} {value:.2f}")
        
        return "\n".join(lines)
    
    def _ascii_agreement_matrix(
        self,
        agreements: dict[str, dict[str, float]],
    ) -> str:
        """Generate ASCII agreement matrix."""
        if not agreements:
            return "  Agreement Matrix\n  No data available"
        
        backends = list(agreements.keys())
        n = len(backends)
        
        # Header
        max_label = max(len(b) for b in backends)
        header = " " * (max_label + 3) + "  ".join(b[:6].ljust(6) for b in backends)
        
        lines = ["  Agreement Matrix (%)", "  " + "=" * 20, header]
        
        for b1 in backends:
            row_values = []
            for b2 in backends:
                val = agreements.get(b1, {}).get(b2, 0)
                row_values.append(f"{val*100:5.1f}%")
            lines.append(f"  {b1.ljust(max_label)}  {' '.join(row_values)}")
        
        return "\n".join(lines)
    
    def _svg_bar_chart(
        self,
        data: dict[str, float],
        title: str,
        width: int = 500,
        height: int = 300,
    ) -> str:
        """Generate SVG bar chart."""
        if not data:
            return f'<svg width="{width}" height="{height}"><text x="10" y="20">No data</text></svg>'
        
        margin = 50
        bar_width = (width - 2 * margin) / len(data)
        max_val = max(data.values()) if data.values() else 1
        
        svg = [
            f'<svg xmlns="http://www.w3.org/2000/svg" width="{width}" height="{height}">',
            '<rect width="100%" height="100%" fill="white"/>',
            f'<text x="{width/2}" y="20" text-anchor="middle" font-weight="bold">{title}</text>',
        ]
        
        for i, (label, value) in enumerate(data.items()):
            x = margin + i * bar_width + bar_width * 0.1
            bar_h = (value / max_val) * (height - 2 * margin - 30) if max_val > 0 else 0
            y = height - margin - bar_h
            color = self.COLORS[i % len(self.COLORS)]
            
            svg.append(
                f'<rect x="{x}" y="{y}" width="{bar_width * 0.8}" height="{bar_h}" '
                f'fill="{color}" rx="3"/>'
            )
            svg.append(
                f'<text x="{x + bar_width * 0.4}" y="{height - margin + 15}" '
                f'text-anchor="middle" font-size="10">{label[:8]}</text>'
            )
            svg.append(
                f'<text x="{x + bar_width * 0.4}" y="{y - 5}" '
                f'text-anchor="middle" font-size="9">{value:.1f}</text>'
            )
        
        svg.append('</svg>')
        return '\n'.join(svg)
    
    def _svg_heatmap(
        self,
        matrix: dict[str, dict[str, float]],
        title: str,
        width: int = 400,
        height: int = 400,
    ) -> str:
        """Generate SVG heatmap for agreement matrix."""
        if not matrix:
            return f'<svg width="{width}" height="{height}"><text x="10" y="20">No data</text></svg>'
        
        backends = list(matrix.keys())
        n = len(backends)
        margin = 80
        cell_size = (min(width, height) - 2 * margin) / n
        
        svg = [
            f'<svg xmlns="http://www.w3.org/2000/svg" width="{width}" height="{height}">',
            '<rect width="100%" height="100%" fill="white"/>',
            f'<text x="{width/2}" y="20" text-anchor="middle" font-weight="bold">{title}</text>',
        ]
        
        # Draw cells
        for i, b1 in enumerate(backends):
            for j, b2 in enumerate(backends):
                value = matrix.get(b1, {}).get(b2, 0)
                x = margin + j * cell_size
                y = margin + i * cell_size
                
                # Color based on value (green gradient)
                intensity = int(value * 200)
                color = f"rgb({255 - intensity}, {155 + intensity // 2}, {155 - intensity // 2})"
                
                svg.append(
                    f'<rect x="{x}" y="{y}" width="{cell_size-1}" height="{cell_size-1}" '
                    f'fill="{color}" stroke="#ccc"/>'
                )
                
                # Value text
                svg.append(
                    f'<text x="{x + cell_size/2}" y="{y + cell_size/2 + 4}" '
                    f'text-anchor="middle" font-size="10">{value*100:.0f}%</text>'
                )
        
        # Row labels
        for i, b in enumerate(backends):
            y = margin + i * cell_size + cell_size / 2 + 4
            svg.append(
                f'<text x="{margin - 5}" y="{y}" text-anchor="end" font-size="10">{b[:10]}</text>'
            )
        
        # Column labels
        for j, b in enumerate(backends):
            x = margin + j * cell_size + cell_size / 2
            svg.append(
                f'<text x="{x}" y="{margin - 5}" text-anchor="middle" font-size="10" '
                f'transform="rotate(-45 {x} {margin - 5})">{b[:10]}</text>'
            )
        
        svg.append('</svg>')
        return '\n'.join(svg)
    
    def _svg_radar_chart(
        self,
        metrics: ComparisonMetrics,
        width: int = 400,
        height: int = 400,
    ) -> str:
        """Generate SVG radar chart for multi-dimensional comparison."""
        if not metrics.execution_times:
            return ""
        
        backends = list(metrics.execution_times.keys())
        if len(backends) < 2:
            return ""
        
        # Normalize metrics to 0-1 scale
        dimensions = ["Speed", "Memory", "Agreement"]
        
        # Calculate scores for each backend
        scores: dict[str, list[float]] = {}
        
        max_time = max(metrics.execution_times.values()) or 1
        max_mem = max(metrics.memory_peaks.values()) if metrics.memory_peaks else 1
        
        for backend in backends:
            time_score = 1 - (metrics.execution_times.get(backend, max_time) / max_time)
            mem_score = 1 - (metrics.memory_peaks.get(backend, max_mem) / max_mem) if max_mem > 0 else 0.5
            
            # Average agreement with other backends
            agreements = metrics.pairwise_agreements.get(backend, {})
            other_agreements = [v for k, v in agreements.items() if k != backend]
            agree_score = sum(other_agreements) / len(other_agreements) if other_agreements else 0.5
            
            scores[backend] = [time_score, mem_score, agree_score]
        
        # Draw radar chart
        center_x, center_y = width / 2, height / 2
        radius = min(width, height) / 2 - 60
        
        import math
        angle_step = 2 * math.pi / len(dimensions)
        
        svg = [
            f'<svg xmlns="http://www.w3.org/2000/svg" width="{width}" height="{height}">',
            '<rect width="100%" height="100%" fill="white"/>',
            f'<text x="{width/2}" y="20" text-anchor="middle" font-weight="bold">Performance Radar</text>',
        ]
        
        # Draw grid
        for level in [0.25, 0.5, 0.75, 1.0]:
            points = []
            for i in range(len(dimensions)):
                angle = i * angle_step - math.pi / 2
                x = center_x + radius * level * math.cos(angle)
                y = center_y + radius * level * math.sin(angle)
                points.append(f"{x},{y}")
            svg.append(
                f'<polygon points="{" ".join(points)}" fill="none" stroke="#ddd"/>'
            )
        
        # Draw axes and labels
        for i, dim in enumerate(dimensions):
            angle = i * angle_step - math.pi / 2
            x = center_x + radius * 1.1 * math.cos(angle)
            y = center_y + radius * 1.1 * math.sin(angle)
            svg.append(
                f'<line x1="{center_x}" y1="{center_y}" x2="{center_x + radius * math.cos(angle)}" '
                f'y2="{center_y + radius * math.sin(angle)}" stroke="#ccc"/>'
            )
            svg.append(
                f'<text x="{x}" y="{y}" text-anchor="middle" font-size="10">{dim}</text>'
            )
        
        # Draw data for each backend
        for idx, (backend, score_list) in enumerate(scores.items()):
            color = self.COLORS[idx % len(self.COLORS)]
            points = []
            for i, score in enumerate(score_list):
                angle = i * angle_step - math.pi / 2
                x = center_x + radius * score * math.cos(angle)
                y = center_y + radius * score * math.sin(angle)
                points.append(f"{x},{y}")
            svg.append(
                f'<polygon points="{" ".join(points)}" fill="{color}" fill-opacity="0.3" '
                f'stroke="{color}" stroke-width="2"/>'
            )
        
        # Legend
        for idx, backend in enumerate(backends):
            color = self.COLORS[idx % len(self.COLORS)]
            y = height - 40 + idx * 15
            svg.append(f'<rect x="10" y="{y}" width="10" height="10" fill="{color}"/>')
            svg.append(f'<text x="25" y="{y + 9}" font-size="10">{backend}</text>')
        
        svg.append('</svg>')
        return '\n'.join(svg)


# =============================================================================
# Result Significance Testing (Feature - Comparison Aggregator)
# =============================================================================


@dataclass
class SignificanceTestSuite:
    """Results from a suite of significance tests."""
    
    t_test: HypothesisTestResult | None = None
    mann_whitney: HypothesisTestResult | None = None
    effect_size: float = 0.0
    power_estimate: float = 0.0
    sample_size_recommendation: int = 0
    overall_conclusion: str = ""


class ResultSignificanceTester:
    """Test statistical significance of comparison results.
    
    Provides:
    - Multiple test battery
    - Effect size calculations
    - Power analysis
    - Sample size recommendations
    - Confidence assessments
    """
    
    def __init__(self, alpha: float = 0.05, power_target: float = 0.8) -> None:
        """Initialize tester.
        
        Args:
            alpha: Significance level
            power_target: Desired statistical power
        """
        self.alpha = alpha
        self.power_target = power_target
        self._analyzer = AdvancedStatisticalAnalyzer(alpha)
    
    def test_execution_time_difference(
        self,
        times_a: list[float],
        times_b: list[float],
        backend_a: str = "Backend A",
        backend_b: str = "Backend B",
    ) -> SignificanceTestSuite:
        """Test if execution time difference is statistically significant.
        
        Runs multiple tests to ensure robust conclusions.
        
        Args:
            times_a: Execution times for first backend
            times_b: Execution times for second backend
            backend_a: Name of first backend
            backend_b: Name of second backend
            
        Returns:
            SignificanceTestSuite with all test results
        """
        suite = SignificanceTestSuite()
        
        if len(times_a) < 2 or len(times_b) < 2:
            suite.overall_conclusion = "Insufficient data for significance testing"
            return suite
        
        # Parametric test (Welch's t-test)
        suite.t_test = self._analyzer.welch_t_test(times_a, times_b)
        
        # Non-parametric test (Mann-Whitney U)
        suite.mann_whitney = self._analyzer.mann_whitney_u_test(times_a, times_b)
        
        # Effect size (Cohen's d)
        suite.effect_size = suite.t_test.effect_size if suite.t_test else 0.0
        
        # Power estimate
        suite.power_estimate = self._estimate_power(
            len(times_a), len(times_b), suite.effect_size
        )
        
        # Sample size recommendation
        suite.sample_size_recommendation = self._recommend_sample_size(suite.effect_size)
        
        # Overall conclusion
        suite.overall_conclusion = self._generate_conclusion(
            suite, backend_a, backend_b, times_a, times_b
        )
        
        return suite
    
    def test_result_agreement_significance(
        self,
        agreements: list[float],
        threshold: float = 0.95,
    ) -> HypothesisTestResult:
        """Test if result agreement is significantly above a threshold.
        
        Uses one-sample t-test against threshold.
        
        Args:
            agreements: List of agreement scores
            threshold: Threshold to test against
            
        Returns:
            HypothesisTestResult
        """
        if len(agreements) < 3:
            return HypothesisTestResult(
                test_name="One-sample t-test",
                statistic=0.0,
                p_value=1.0,
                significant=False,
                effect_size=0.0,
                interpretation="Insufficient data",
            )
        
        arr = np.array(agreements)
        n = len(arr)
        mean = np.mean(arr)
        std = np.std(arr, ddof=1)
        
        if std == 0:
            significant = mean > threshold
            return HypothesisTestResult(
                test_name="One-sample t-test",
                statistic=float('inf') if mean > threshold else float('-inf'),
                p_value=0.0 if mean > threshold else 1.0,
                significant=significant,
                effect_size=0.0,
                interpretation=f"All values equal to {mean:.3f}",
            )
        
        t_stat = (mean - threshold) / (std / np.sqrt(n))
        p_value = self._analyzer._t_distribution_pvalue(float(t_stat), n - 1, "greater")
        
        effect_size = (mean - threshold) / std
        significant = p_value < self.alpha
        
        if significant:
            interpretation = f"Agreement ({mean:.1%}) is significantly above {threshold:.0%} (p={p_value:.4f})"
        else:
            interpretation = f"Agreement ({mean:.1%}) is not significantly above {threshold:.0%} (p={p_value:.4f})"
        
        return HypothesisTestResult(
            test_name="One-sample t-test (vs threshold)",
            statistic=float(t_stat),
            p_value=p_value,
            significant=significant,
            effect_size=abs(effect_size),
            interpretation=interpretation,
        )
    
    def _estimate_power(self, n1: int, n2: int, effect_size: float) -> float:
        """Estimate statistical power given sample sizes and effect size."""
        if effect_size == 0:
            return self.alpha  # Power equals alpha when no effect
        
        # Simplified power calculation
        # In production, use scipy.stats.power
        n = 2 / (1/n1 + 1/n2)  # Harmonic mean
        ncp = effect_size * np.sqrt(n / 2)  # Non-centrality parameter
        
        # Rough approximation using normal distribution
        from math import erf, sqrt
        z_alpha = 1.96 if self.alpha == 0.05 else 1.645
        power = 0.5 * (1 + erf((ncp - z_alpha) / sqrt(2)))
        
        return min(0.99, max(0.01, power))
    
    def _recommend_sample_size(self, effect_size: float) -> int:
        """Recommend sample size for desired power."""
        if effect_size == 0:
            return 100  # Default for unknown effect
        
        # Sample size formula for two-sample t-test
        # n = 2 * ((z_alpha + z_beta) / d)^2
        z_alpha = 1.96  # For alpha = 0.05
        z_beta = 0.84   # For power = 0.8
        
        n_per_group = 2 * ((z_alpha + z_beta) / effect_size) ** 2
        
        return max(10, int(np.ceil(n_per_group)))
    
    def _generate_conclusion(
        self,
        suite: SignificanceTestSuite,
        backend_a: str,
        backend_b: str,
        times_a: list[float],
        times_b: list[float],
    ) -> str:
        """Generate overall conclusion from test suite."""
        mean_a = np.mean(times_a)
        mean_b = np.mean(times_b)
        
        # Check agreement between tests
        t_sig = suite.t_test.significant if suite.t_test else False
        mw_sig = suite.mann_whitney.significant if suite.mann_whitney else False
        
        conclusions = []
        
        if t_sig and mw_sig:
            faster = backend_a if mean_a < mean_b else backend_b
            conclusions.append(
                f"Both parametric and non-parametric tests agree: "
                f"{faster} is significantly faster."
            )
        elif t_sig or mw_sig:
            conclusions.append(
                "Tests show mixed results. Consider collecting more data."
            )
        else:
            conclusions.append(
                f"No significant difference detected between {backend_a} and {backend_b}."
            )
        
        # Effect size interpretation
        effect_interp = self._analyzer._interpret_effect_size(suite.effect_size)
        conclusions.append(f"Effect size: {effect_interp} (d={suite.effect_size:.2f})")
        
        # Power assessment
        if suite.power_estimate < 0.5:
            conclusions.append(
                f" Low statistical power ({suite.power_estimate:.0%}). "
                f"Recommend {suite.sample_size_recommendation} samples per backend."
            )
        elif suite.power_estimate < self.power_target:
            conclusions.append(
                f"Moderate power ({suite.power_estimate:.0%}). "
                f"Consider {suite.sample_size_recommendation} samples for more reliable results."
            )
        else:
            conclusions.append(f"Good statistical power ({suite.power_estimate:.0%}).")
        
        return " ".join(conclusions)


# =============================================================================
# ENHANCED VISUALIZATION (2% Gap Coverage)
# =============================================================================


class ChartExportFormat(Enum):
    """Supported export formats for charts."""
    
    SVG = "svg"
    PNG = "png"
    PDF = "pdf"
    HTML = "html"
    JSON = "json"


class AnimationType(Enum):
    """Types of chart animations."""
    
    NONE = "none"
    FADE_IN = "fade_in"
    SLIDE_UP = "slide_up"
    GROW = "grow"
    SEQUENTIAL = "sequential"


@dataclass
class InteractiveFeatures:
    """Configuration for interactive visualization features."""
    
    tooltips: bool = True
    zoom: bool = True
    pan: bool = True
    hover_highlight: bool = True
    click_select: bool = True
    legend_toggle: bool = True
    crosshair: bool = False
    data_labels: bool = True


@dataclass
class ChartTheme:
    """Theme configuration for charts."""
    
    name: str = "default"
    background_color: str = "#ffffff"
    text_color: str = "#333333"
    grid_color: str = "#e0e0e0"
    axis_color: str = "#666666"
    colors: list[str] = field(default_factory=lambda: [
        "#3498db", "#2ecc71", "#e74c3c", "#f39c12",
        "#9b59b6", "#1abc9c", "#34495e", "#e67e22",
    ])
    font_family: str = "Arial, sans-serif"
    font_size: int = 12
    
    @classmethod
    def dark_theme(cls) -> ChartTheme:
        """Create a dark theme."""
        return cls(
            name="dark",
            background_color="#1a1a2e",
            text_color="#ecf0f1",
            grid_color="#2c3e50",
            axis_color="#95a5a6",
            colors=[
                "#5dade2", "#58d68d", "#ec7063", "#f4d03f",
                "#af7ac5", "#45b39d", "#5d6d7e", "#eb984e",
            ],
        )
    
    @classmethod
    def high_contrast(cls) -> ChartTheme:
        """Create a high contrast theme."""
        return cls(
            name="high_contrast",
            background_color="#000000",
            text_color="#ffffff",
            grid_color="#444444",
            axis_color="#ffffff",
            colors=[
                "#00ff00", "#ff0000", "#0000ff", "#ffff00",
                "#ff00ff", "#00ffff", "#ff8000", "#8000ff",
            ],
        )


@dataclass
class EnhancedVisualization:
    """Container for enhanced visualizations with metadata."""
    
    chart_type: str
    format: str
    content: str
    width: int
    height: int
    interactive: bool = False
    animation: AnimationType = AnimationType.NONE
    theme: str = "default"
    metadata: dict[str, Any] = field(default_factory=dict)
    
    def to_dict(self) -> dict[str, Any]:
        """Convert to dictionary."""
        return {
            "chart_type": self.chart_type,
            "format": self.format,
            "width": self.width,
            "height": self.height,
            "interactive": self.interactive,
            "animation": self.animation.value,
            "theme": self.theme,
            "metadata": self.metadata,
        }


class EnhancedComparisonVisualizer:
    """Enhanced visualizer with interactive features and export capabilities.
    
    Features:
    - Interactive charts with tooltips, zoom, pan
    - Multiple export formats (SVG, PNG, PDF, HTML)
    - Animation support
    - Customizable themes
    - Additional chart types (line, scatter, box plot, violin)
    - Time-series comparison animations
    """
    
    def __init__(
        self,
        theme: ChartTheme | None = None,
        interactive: InteractiveFeatures | None = None,
        animation: AnimationType = AnimationType.NONE,
    ) -> None:
        """Initialize enhanced visualizer.
        
        Args:
            theme: Chart theme configuration
            interactive: Interactive features configuration
            animation: Default animation type
        """
        self.theme = theme or ChartTheme()
        self.interactive = interactive or InteractiveFeatures()
        self.animation = animation
        self._base_visualizer = ComparisonVisualizer()
    
    def generate_line_chart(
        self,
        data: dict[str, list[float]],
        title: str,
        x_labels: list[str] | None = None,
        width: int = 600,
        height: int = 400,
    ) -> EnhancedVisualization:
        """Generate line chart for time-series data.
        
        Args:
            data: Backend name -> list of values
            title: Chart title
            x_labels: Labels for x-axis
            width: Chart width
            height: Chart height
            
        Returns:
            EnhancedVisualization with SVG content
        """
        if not data:
            return EnhancedVisualization(
                chart_type="line",
                format="svg",
                content=self._empty_chart(title, width, height),
                width=width,
                height=height,
            )
        
        margin = {"top": 40, "right": 120, "bottom": 50, "left": 60}
        plot_width = width - margin["left"] - margin["right"]
        plot_height = height - margin["top"] - margin["bottom"]
        
        # Find data range
        all_values = [v for vals in data.values() for v in vals]
        max_val = max(all_values) if all_values else 1
        min_val = min(all_values) if all_values else 0
        max_len = max(len(vals) for vals in data.values())
        
        svg_parts = [
            f'<svg xmlns="http://www.w3.org/2000/svg" width="{width}" height="{height}">',
            f'<rect width="100%" height="100%" fill="{self.theme.background_color}"/>',
            f'<text x="{width/2}" y="25" text-anchor="middle" font-weight="bold" '
            f'fill="{self.theme.text_color}" font-family="{self.theme.font_family}">{title}</text>',
        ]
        
        # Draw grid
        for i in range(5):
            y = margin["top"] + (plot_height / 4) * i
            svg_parts.append(
                f'<line x1="{margin["left"]}" y1="{y}" x2="{margin["left"] + plot_width}" y2="{y}" '
                f'stroke="{self.theme.grid_color}" stroke-dasharray="3,3"/>'
            )
            value = max_val - (max_val - min_val) * i / 4
            svg_parts.append(
                f'<text x="{margin["left"] - 5}" y="{y + 4}" text-anchor="end" font-size="10" '
                f'fill="{self.theme.text_color}">{value:.1f}</text>'
            )
        
        # Draw lines for each backend
        for idx, (backend, values) in enumerate(data.items()):
            color = self.theme.colors[idx % len(self.theme.colors)]
            points = []
            
            for i, val in enumerate(values):
                x = margin["left"] + (plot_width / (max_len - 1)) * i if max_len > 1 else margin["left"]
                y = margin["top"] + plot_height - ((val - min_val) / (max_val - min_val)) * plot_height if max_val > min_val else margin["top"] + plot_height / 2
                points.append(f"{x},{y}")
                
                # Add data points
                if self.interactive.data_labels:
                    svg_parts.append(
                        f'<circle cx="{x}" cy="{y}" r="4" fill="{color}" '
                        f'stroke="{self.theme.background_color}" stroke-width="2">'
                    )
                    if self.interactive.tooltips:
                        svg_parts.append(f'<title>{backend}: {val:.2f}</title>')
                    svg_parts.append('</circle>')
            
            # Draw line
            if points:
                svg_parts.append(
                    f'<polyline points="{" ".join(points)}" fill="none" '
                    f'stroke="{color}" stroke-width="2"/>'
                )
        
        # Legend
        for idx, backend in enumerate(data.keys()):
            color = self.theme.colors[idx % len(self.theme.colors)]
            y = margin["top"] + 20 + idx * 20
            svg_parts.append(
                f'<rect x="{width - margin["right"] + 10}" y="{y}" width="15" height="3" fill="{color}"/>'
            )
            svg_parts.append(
                f'<text x="{width - margin["right"] + 30}" y="{y + 4}" font-size="10" '
                f'fill="{self.theme.text_color}">{backend}</text>'
            )
        
        svg_parts.append('</svg>')
        
        return EnhancedVisualization(
            chart_type="line",
            format="svg",
            content='\n'.join(svg_parts),
            width=width,
            height=height,
            interactive=self.interactive.tooltips,
            animation=self.animation,
            theme=self.theme.name,
        )
    
    def generate_scatter_plot(
        self,
        x_data: dict[str, float],
        y_data: dict[str, float],
        title: str,
        x_label: str = "X",
        y_label: str = "Y",
        width: int = 500,
        height: int = 400,
    ) -> EnhancedVisualization:
        """Generate scatter plot for two-dimensional comparison.
        
        Args:
            x_data: Backend name -> x value
            y_data: Backend name -> y value
            title: Chart title
            x_label: X-axis label
            y_label: Y-axis label
            width: Chart width
            height: Chart height
            
        Returns:
            EnhancedVisualization with scatter plot
        """
        margin = {"top": 40, "right": 80, "bottom": 50, "left": 60}
        plot_width = width - margin["left"] - margin["right"]
        plot_height = height - margin["top"] - margin["bottom"]
        
        backends = list(set(x_data.keys()) & set(y_data.keys()))
        if not backends:
            return EnhancedVisualization(
                chart_type="scatter",
                format="svg",
                content=self._empty_chart(title, width, height),
                width=width,
                height=height,
            )
        
        x_vals = [x_data[b] for b in backends]
        y_vals = [y_data[b] for b in backends]
        
        x_min, x_max = min(x_vals), max(x_vals)
        y_min, y_max = min(y_vals), max(y_vals)
        
        # Add padding
        x_range = x_max - x_min or 1
        y_range = y_max - y_min or 1
        x_min -= x_range * 0.1
        x_max += x_range * 0.1
        y_min -= y_range * 0.1
        y_max += y_range * 0.1
        
        svg_parts = [
            f'<svg xmlns="http://www.w3.org/2000/svg" width="{width}" height="{height}">',
            f'<rect width="100%" height="100%" fill="{self.theme.background_color}"/>',
            f'<text x="{width/2}" y="25" text-anchor="middle" font-weight="bold" '
            f'fill="{self.theme.text_color}">{title}</text>',
        ]
        
        # Axes
        svg_parts.append(
            f'<line x1="{margin["left"]}" y1="{margin["top"] + plot_height}" '
            f'x2="{margin["left"] + plot_width}" y2="{margin["top"] + plot_height}" '
            f'stroke="{self.theme.axis_color}" stroke-width="2"/>'
        )
        svg_parts.append(
            f'<line x1="{margin["left"]}" y1="{margin["top"]}" '
            f'x2="{margin["left"]}" y2="{margin["top"] + plot_height}" '
            f'stroke="{self.theme.axis_color}" stroke-width="2"/>'
        )
        
        # Axis labels
        svg_parts.append(
            f'<text x="{margin["left"] + plot_width/2}" y="{height - 10}" text-anchor="middle" '
            f'fill="{self.theme.text_color}">{x_label}</text>'
        )
        svg_parts.append(
            f'<text x="15" y="{margin["top"] + plot_height/2}" text-anchor="middle" '
            f'transform="rotate(-90 15 {margin["top"] + plot_height/2})" '
            f'fill="{self.theme.text_color}">{y_label}</text>'
        )
        
        # Plot points
        for idx, backend in enumerate(backends):
            x = margin["left"] + ((x_data[backend] - x_min) / (x_max - x_min)) * plot_width
            y = margin["top"] + plot_height - ((y_data[backend] - y_min) / (y_max - y_min)) * plot_height
            color = self.theme.colors[idx % len(self.theme.colors)]
            
            svg_parts.append(
                f'<circle cx="{x}" cy="{y}" r="8" fill="{color}" opacity="0.8">'
            )
            if self.interactive.tooltips:
                svg_parts.append(
                    f'<title>{backend}: ({x_data[backend]:.2f}, {y_data[backend]:.2f})</title>'
                )
            svg_parts.append('</circle>')
            
            # Label
            svg_parts.append(
                f'<text x="{x + 10}" y="{y - 10}" font-size="10" '
                f'fill="{self.theme.text_color}">{backend}</text>'
            )
        
        svg_parts.append('</svg>')
        
        return EnhancedVisualization(
            chart_type="scatter",
            format="svg",
            content='\n'.join(svg_parts),
            width=width,
            height=height,
            interactive=self.interactive.tooltips,
        )
    
    def generate_box_plot(
        self,
        data: dict[str, list[float]],
        title: str,
        y_label: str = "Value",
        width: int = 500,
        height: int = 400,
    ) -> EnhancedVisualization:
        """Generate box plot for distribution comparison.
        
        Args:
            data: Backend name -> list of values
            title: Chart title
            y_label: Y-axis label
            width: Chart width
            height: Chart height
            
        Returns:
            EnhancedVisualization with box plot
        """
        if not data:
            return EnhancedVisualization(
                chart_type="box",
                format="svg",
                content=self._empty_chart(title, width, height),
                width=width,
                height=height,
            )
        
        margin = {"top": 40, "right": 40, "bottom": 60, "left": 60}
        plot_width = width - margin["left"] - margin["right"]
        plot_height = height - margin["top"] - margin["bottom"]
        
        # Calculate statistics
        all_values = [v for vals in data.values() for v in vals]
        y_min = min(all_values) - 0.1 * (max(all_values) - min(all_values))
        y_max = max(all_values) + 0.1 * (max(all_values) - min(all_values))
        y_range = y_max - y_min or 1
        
        box_width = plot_width / (len(data) + 1)
        
        svg_parts = [
            f'<svg xmlns="http://www.w3.org/2000/svg" width="{width}" height="{height}">',
            f'<rect width="100%" height="100%" fill="{self.theme.background_color}"/>',
            f'<text x="{width/2}" y="25" text-anchor="middle" font-weight="bold" '
            f'fill="{self.theme.text_color}">{title}</text>',
        ]
        
        for idx, (backend, values) in enumerate(data.items()):
            if len(values) < 2:
                continue
            
            arr = np.array(sorted(values))
            q1 = float(np.percentile(arr, 25))
            q2 = float(np.percentile(arr, 50))  # median
            q3 = float(np.percentile(arr, 75))
            iqr = q3 - q1
            whisker_low = max(arr.min(), q1 - 1.5 * iqr)
            whisker_high = min(arr.max(), q3 + 1.5 * iqr)
            
            x_center = margin["left"] + box_width * (idx + 1)
            color = self.theme.colors[idx % len(self.theme.colors)]
            
            def y_scale(val: float) -> float:
                return margin["top"] + plot_height - ((val - y_min) / y_range) * plot_height
            
            # Whiskers
            svg_parts.append(
                f'<line x1="{x_center}" y1="{y_scale(whisker_low)}" '
                f'x2="{x_center}" y2="{y_scale(q1)}" stroke="{color}" stroke-width="1"/>'
            )
            svg_parts.append(
                f'<line x1="{x_center}" y1="{y_scale(q3)}" '
                f'x2="{x_center}" y2="{y_scale(whisker_high)}" stroke="{color}" stroke-width="1"/>'
            )
            
            # Whisker caps
            cap_width = box_width * 0.2
            svg_parts.append(
                f'<line x1="{x_center - cap_width}" y1="{y_scale(whisker_low)}" '
                f'x2="{x_center + cap_width}" y2="{y_scale(whisker_low)}" stroke="{color}" stroke-width="1"/>'
            )
            svg_parts.append(
                f'<line x1="{x_center - cap_width}" y1="{y_scale(whisker_high)}" '
                f'x2="{x_center + cap_width}" y2="{y_scale(whisker_high)}" stroke="{color}" stroke-width="1"/>'
            )
            
            # Box
            box_half = box_width * 0.35
            svg_parts.append(
                f'<rect x="{x_center - box_half}" y="{y_scale(q3)}" '
                f'width="{box_half * 2}" height="{y_scale(q1) - y_scale(q3)}" '
                f'fill="{color}" fill-opacity="0.5" stroke="{color}" stroke-width="2"/>'
            )
            
            # Median line
            svg_parts.append(
                f'<line x1="{x_center - box_half}" y1="{y_scale(q2)}" '
                f'x2="{x_center + box_half}" y2="{y_scale(q2)}" '
                f'stroke="{self.theme.background_color}" stroke-width="2"/>'
            )
            
            # Label
            svg_parts.append(
                f'<text x="{x_center}" y="{height - margin["bottom"] + 20}" '
                f'text-anchor="middle" font-size="10" fill="{self.theme.text_color}">{backend}</text>'
            )
        
        # Y-axis label
        svg_parts.append(
            f'<text x="15" y="{margin["top"] + plot_height/2}" text-anchor="middle" '
            f'transform="rotate(-90 15 {margin["top"] + plot_height/2})" '
            f'fill="{self.theme.text_color}">{y_label}</text>'
        )
        
        svg_parts.append('</svg>')
        
        return EnhancedVisualization(
            chart_type="box",
            format="svg",
            content='\n'.join(svg_parts),
            width=width,
            height=height,
        )
    
    def generate_animated_comparison(
        self,
        time_series: dict[str, list[tuple[float, float]]],
        title: str,
        width: int = 600,
        height: int = 400,
        duration_ms: int = 2000,
    ) -> EnhancedVisualization:
        """Generate animated comparison showing performance over time.
        
        Args:
            time_series: Backend name -> list of (timestamp, value) tuples
            title: Chart title
            width: Chart width
            height: Chart height
            duration_ms: Animation duration in milliseconds
            
        Returns:
            EnhancedVisualization with animated SVG
        """
        margin = {"top": 40, "right": 120, "bottom": 50, "left": 60}
        plot_width = width - margin["left"] - margin["right"]
        plot_height = height - margin["top"] - margin["bottom"]
        
        if not time_series:
            return EnhancedVisualization(
                chart_type="animated_line",
                format="svg",
                content=self._empty_chart(title, width, height),
                width=width,
                height=height,
            )
        
        # Find ranges
        all_times = [t for series in time_series.values() for t, _ in series]
        all_values = [v for series in time_series.values() for _, v in series]
        
        t_min, t_max = min(all_times), max(all_times)
        v_min, v_max = min(all_values), max(all_values)
        t_range = t_max - t_min or 1
        v_range = v_max - v_min or 1
        
        svg_parts = [
            f'<svg xmlns="http://www.w3.org/2000/svg" width="{width}" height="{height}">',
            '<defs>',
            '<style>',
            '@keyframes drawLine { from { stroke-dashoffset: 1000; } to { stroke-dashoffset: 0; } }',
            '@keyframes fadeIn { from { opacity: 0; } to { opacity: 1; } }',
            '</style>',
            '</defs>',
            f'<rect width="100%" height="100%" fill="{self.theme.background_color}"/>',
            f'<text x="{width/2}" y="25" text-anchor="middle" font-weight="bold" '
            f'fill="{self.theme.text_color}">{title}</text>',
        ]
        
        # Draw grid
        for i in range(5):
            y = margin["top"] + (plot_height / 4) * i
            svg_parts.append(
                f'<line x1="{margin["left"]}" y1="{y}" x2="{margin["left"] + plot_width}" y2="{y}" '
                f'stroke="{self.theme.grid_color}" stroke-dasharray="3,3"/>'
            )
        
        # Draw animated lines
        for idx, (backend, series) in enumerate(time_series.items()):
            color = self.theme.colors[idx % len(self.theme.colors)]
            points = []
            
            for t, v in sorted(series):
                x = margin["left"] + ((t - t_min) / t_range) * plot_width
                y = margin["top"] + plot_height - ((v - v_min) / v_range) * plot_height
                points.append(f"{x},{y}")
            
            if points:
                delay = idx * 300  # Stagger animation
                svg_parts.append(
                    f'<polyline points="{" ".join(points)}" fill="none" '
                    f'stroke="{color}" stroke-width="2" '
                    f'stroke-dasharray="1000" stroke-dashoffset="1000" '
                    f'style="animation: drawLine {duration_ms}ms ease-out {delay}ms forwards;"/>'
                )
        
        # Animated legend
        for idx, backend in enumerate(time_series.keys()):
            color = self.theme.colors[idx % len(self.theme.colors)]
            y = margin["top"] + 20 + idx * 20
            delay = idx * 300
            svg_parts.append(
                f'<g style="opacity: 0; animation: fadeIn 500ms ease-out {delay}ms forwards;">'
                f'<rect x="{width - margin["right"] + 10}" y="{y}" width="15" height="3" fill="{color}"/>'
                f'<text x="{width - margin["right"] + 30}" y="{y + 4}" font-size="10" '
                f'fill="{self.theme.text_color}">{backend}</text>'
                f'</g>'
            )
        
        svg_parts.append('</svg>')
        
        return EnhancedVisualization(
            chart_type="animated_line",
            format="svg",
            content='\n'.join(svg_parts),
            width=width,
            height=height,
            animation=AnimationType.SEQUENTIAL,
            metadata={"duration_ms": duration_ms},
        )
    
    def export_chart(
        self,
        visualization: EnhancedVisualization,
        output_path: Path,
        format: ChartExportFormat | None = None,
    ) -> bool:
        """Export chart to file.
        
        Args:
            visualization: Visualization to export
            output_path: Output file path
            format: Export format (inferred from path if not specified)
            
        Returns:
            True if export successful
        """
        if format is None:
            suffix = output_path.suffix.lower()
            format_map = {
                '.svg': ChartExportFormat.SVG,
                '.png': ChartExportFormat.PNG,
                '.pdf': ChartExportFormat.PDF,
                '.html': ChartExportFormat.HTML,
                '.json': ChartExportFormat.JSON,
            }
            format = format_map.get(suffix, ChartExportFormat.SVG)
        
        try:
            if format == ChartExportFormat.SVG:
                output_path.write_text(visualization.content)
            
            elif format == ChartExportFormat.HTML:
                html_content = f"""<!DOCTYPE html>
<html>
<head>
    <title>{visualization.chart_type} Chart</title>
    <style>
        body {{ display: flex; justify-content: center; padding: 20px; }}
        .chart-container {{ max-width: 100%; }}
    </style>
</head>
<body>
    <div class="chart-container">
        {visualization.content}
    </div>
</body>
</html>"""
                output_path.write_text(html_content)
            
            elif format == ChartExportFormat.JSON:
                import json
                json_data = {
                    "chart": visualization.to_dict(),
                    "svg_content": visualization.content,
                }
                output_path.write_text(json.dumps(json_data, indent=2))
            
            elif format in (ChartExportFormat.PNG, ChartExportFormat.PDF):
                # For PNG/PDF, we'd need external library (cairosvg, svglib)
                # For now, save as SVG with note
                svg_path = output_path.with_suffix('.svg')
                svg_path.write_text(visualization.content)
                # Create a placeholder note
                output_path.write_text(
                    f"SVG saved to: {svg_path}\n"
                    f"Note: PNG/PDF conversion requires cairosvg or svglib library."
                )
            
            return True
        except Exception:
            return False
    
    def generate_interactive_html(
        self,
        metrics: ComparisonMetrics,
        title: str = "Backend Comparison",
    ) -> str:
        """Generate fully interactive HTML visualization.
        
        Creates an HTML page with JavaScript-powered interactivity.
        
        Args:
            metrics: Comparison metrics to visualize
            title: Page title
            
        Returns:
            HTML content string
        """
        # Convert data to JSON for JavaScript
        import json
        
        chart_data = {
            "execution_times": metrics.execution_times,
            "memory_peaks": metrics.memory_peaks,
            "agreements": metrics.pairwise_agreements,
            "time_ratios": metrics.time_ratios,
        }
        
        html = f"""<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{title}</title>
    <style>
        * {{ box-sizing: border-box; }}
        body {{
            font-family: {self.theme.font_family};
            background: {self.theme.background_color};
            color: {self.theme.text_color};
            margin: 0;
            padding: 20px;
        }}
        .dashboard {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(400px, 1fr));
            gap: 20px;
            max-width: 1400px;
            margin: 0 auto;
        }}
        .chart-card {{
            background: {'#16213e' if self.theme.name == 'dark' else '#f5f5f5'};
            border-radius: 8px;
            padding: 20px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.2);
        }}
        .chart-card h3 {{
            margin: 0 0 15px 0;
            font-size: 16px;
        }}
        .chart-container {{
            position: relative;
            height: 300px;
        }}
        .bar {{
            transition: opacity 0.2s;
            cursor: pointer;
        }}
        .bar:hover {{
            opacity: 0.8;
        }}
        .tooltip {{
            position: absolute;
            background: rgba(0,0,0,0.8);
            color: white;
            padding: 8px 12px;
            border-radius: 4px;
            font-size: 12px;
            pointer-events: none;
            opacity: 0;
            transition: opacity 0.2s;
            z-index: 100;
        }}
        .tooltip.visible {{
            opacity: 1;
        }}
        .legend {{
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            margin-top: 10px;
        }}
        .legend-item {{
            display: flex;
            align-items: center;
            gap: 5px;
            font-size: 12px;
            cursor: pointer;
        }}
        .legend-color {{
            width: 12px;
            height: 12px;
            border-radius: 2px;
        }}
        .controls {{
            margin-bottom: 20px;
            display: flex;
            gap: 10px;
        }}
        button {{
            background: #3498db;
            color: white;
            border: none;
            padding: 8px 16px;
            border-radius: 4px;
            cursor: pointer;
        }}
        button:hover {{
            background: #2980b9;
        }}
        h1 {{
            text-align: center;
            margin-bottom: 30px;
        }}
    </style>
</head>
<body>
    <h1>{title}</h1>
    
    <div class="controls">
        <button onclick="toggleTheme()">Toggle Theme</button>
        <button onclick="exportData()">Export Data (JSON)</button>
        <button onclick="printDashboard()">Print / Save as PDF</button>
    </div>
    
    <div class="dashboard">
        <div class="chart-card">
            <h3> Execution Times (ms)</h3>
            <div class="chart-container" id="time-chart"></div>
        </div>
        <div class="chart-card">
            <h3> Memory Usage (MB)</h3>
            <div class="chart-container" id="memory-chart"></div>
        </div>
        <div class="chart-card">
            <h3> Result Agreement</h3>
            <div class="chart-container" id="agreement-chart"></div>
        </div>
        <div class="chart-card">
            <h3> Performance Ratio</h3>
            <div class="chart-container" id="ratio-chart"></div>
        </div>
    </div>
    
    <div class="tooltip" id="tooltip"></div>
    
    <script>
        const data = {json.dumps(chart_data)};
        const colors = {json.dumps(self.theme.colors)};
        
        function createBarChart(containerId, chartData, unit) {{
            const container = document.getElementById(containerId);
            const entries = Object.entries(chartData);
            if (entries.length === 0) {{
                container.innerHTML = '<p>No data available</p>';
                return;
            }}
            
            const maxVal = Math.max(...entries.map(([_, v]) => v));
            const barWidth = 100 / entries.length;
            
            let html = '<svg width="100%" height="100%" viewBox="0 0 400 280">';
            
            entries.forEach(([name, value], i) => {{
                const barHeight = (value / maxVal) * 200;
                const x = 50 + i * (300 / entries.length);
                const y = 250 - barHeight;
                const color = colors[i % colors.length];
                
                html += `
                    <rect class="bar" x="${{x}}" y="${{y}}" width="${{250/entries.length - 10}}" 
                          height="${{barHeight}}" fill="${{color}}"
                          onmouseover="showTooltip(event, '${{name}}: ${{value.toFixed(2)}} ${{unit}}')"
                          onmouseout="hideTooltip()"/>
                    <text x="${{x + (250/entries.length - 10)/2}}" y="270" 
                          text-anchor="middle" font-size="10" fill="{self.theme.text_color}">${{name.slice(0,8)}}</text>
                `;
            }});
            
            html += '</svg>';
            container.innerHTML = html;
        }}
        
        function showTooltip(event, text) {{
            const tooltip = document.getElementById('tooltip');
            tooltip.textContent = text;
            tooltip.style.left = (event.pageX + 10) + 'px';
            tooltip.style.top = (event.pageY - 30) + 'px';
            tooltip.classList.add('visible');
        }}
        
        function hideTooltip() {{
            document.getElementById('tooltip').classList.remove('visible');
        }}
        
        function toggleTheme() {{
            document.body.style.background = 
                document.body.style.background === 'rgb(26, 26, 46)' ? '#ffffff' : '#1a1a2e';
            document.body.style.color = 
                document.body.style.color === 'rgb(236, 240, 241)' ? '#333333' : '#ecf0f1';
        }}
        
        function exportData() {{
            const blob = new Blob([JSON.stringify(data, null, 2)], {{type: 'application/json'}});
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = 'comparison_data.json';
            a.click();
        }}
        
        function printDashboard() {{
            window.print();
        }}
        
        // Initialize charts
        createBarChart('time-chart', data.execution_times, 'ms');
        createBarChart('memory-chart', data.memory_peaks, 'MB');
        createBarChart('ratio-chart', data.time_ratios, 'x');
        
        // Agreement heatmap would require more complex rendering
        if (Object.keys(data.agreements).length > 0) {{
            document.getElementById('agreement-chart').innerHTML = 
                '<p style="text-align:center">See detailed agreement matrix in full report</p>';
        }}
    </script>
</body>
</html>"""
        
        return html
    
    def _empty_chart(self, title: str, width: int, height: int) -> str:
        """Generate empty chart placeholder."""
        return f'''<svg xmlns="http://www.w3.org/2000/svg" width="{width}" height="{height}">
            <rect width="100%" height="100%" fill="{self.theme.background_color}"/>
            <text x="{width/2}" y="{height/2}" text-anchor="middle" 
                  fill="{self.theme.text_color}">No data available</text>
        </svg>'''


# =============================================================================
# Advanced Visualization Generation (Feature - 2% Gap Completion)
# =============================================================================


@dataclass
class ChartExportOptions:
    """Options for chart export."""
    
    format: str = "svg"  # 'svg', 'png', 'html', 'ascii'
    width: int = 800
    height: int = 600
    dpi: int = 96
    background_transparent: bool = False
    embed_fonts: bool = True
    include_legend: bool = True
    include_title: bool = True


@dataclass
class VisualizationReport:
    """Complete visualization report container."""
    
    title: str
    generated_at: datetime
    charts: dict[str, str]  # chart_name -> content (SVG/ASCII)
    html_report: str
    insights: list[str]
    summary_stats: dict[str, Any]
    export_formats_available: list[str] = field(default_factory=lambda: ["svg", "html", "ascii"])


class AdvancedVisualizationGenerator:
    """Advanced visualization generation with multiple chart types.
    
    Provides:
    - Scatter plots for correlation analysis
    - Line charts for trend visualization
    - Histograms for distribution analysis
    - Box plots for statistical summaries
    - Stacked bar charts for composition
    - Area charts for cumulative views
    - Complete report generation
    """
    
    CHART_COLORS = [
        "#3498db", "#2ecc71", "#e74c3c", "#f39c12",
        "#9b59b6", "#1abc9c", "#34495e", "#e67e22",
        "#16a085", "#c0392b", "#2c3e50", "#d35400",
    ]
    
    def __init__(
        self,
        theme: str = "light",
        font_family: str = "Arial, sans-serif",
    ) -> None:
        """Initialize visualization generator.
        
        Args:
            theme: 'light' or 'dark' theme
            font_family: Font family for text
        """
        self.theme = theme
        self.font_family = font_family
        self._bg_color = "#ffffff" if theme == "light" else "#1a1a2e"
        self._text_color = "#333333" if theme == "light" else "#ecf0f1"
        self._grid_color = "#e0e0e0" if theme == "light" else "#3d3d5c"
    
    def generate_scatter_plot(
        self,
        x_data: dict[str, float],
        y_data: dict[str, float],
        x_label: str = "X",
        y_label: str = "Y",
        title: str = "Scatter Plot",
        width: int = 500,
        height: int = 400,
    ) -> str:
        """Generate SVG scatter plot for correlation visualization.
        
        Args:
            x_data: X-axis values by backend name
            y_data: Y-axis values by backend name
            x_label: Label for X axis
            y_label: Label for Y axis
            title: Chart title
            width: Chart width
            height: Chart height
            
        Returns:
            SVG string
        """
        if not x_data or not y_data:
            return self._empty_svg(title, width, height)
        
        margin = 60
        plot_width = width - 2 * margin
        plot_height = height - 2 * margin - 30
        
        # Get common backends
        common_backends = set(x_data.keys()) & set(y_data.keys())
        if not common_backends:
            return self._empty_svg(title, width, height)
        
        # Calculate scales
        x_values = [x_data[b] for b in common_backends]
        y_values = [y_data[b] for b in common_backends]
        
        x_min, x_max = min(x_values), max(x_values)
        y_min, y_max = min(y_values), max(y_values)
        
        # Add padding to ranges
        x_range = (x_max - x_min) or 1
        y_range = (y_max - y_min) or 1
        x_min -= x_range * 0.1
        x_max += x_range * 0.1
        y_min -= y_range * 0.1
        y_max += y_range * 0.1
        
        def scale_x(val: float) -> float:
            return margin + ((val - x_min) / (x_max - x_min)) * plot_width
        
        def scale_y(val: float) -> float:
            return height - margin - ((val - y_min) / (y_max - y_min)) * plot_height
        
        svg = [
            f'<svg xmlns="http://www.w3.org/2000/svg" width="{width}" height="{height}">',
            f'<rect width="100%" height="100%" fill="{self._bg_color}"/>',
            f'<text x="{width/2}" y="25" text-anchor="middle" font-weight="bold" '
            f'fill="{self._text_color}" font-family="{self.font_family}">{title}</text>',
        ]
        
        # Draw axes
        svg.append(
            f'<line x1="{margin}" y1="{height - margin}" x2="{width - margin}" '
            f'y2="{height - margin}" stroke="{self._text_color}"/>'
        )
        svg.append(
            f'<line x1="{margin}" y1="{margin}" x2="{margin}" '
            f'y2="{height - margin}" stroke="{self._text_color}"/>'
        )
        
        # Axis labels
        svg.append(
            f'<text x="{width/2}" y="{height - 10}" text-anchor="middle" '
            f'fill="{self._text_color}" font-size="12">{x_label}</text>'
        )
        svg.append(
            f'<text x="15" y="{height/2}" text-anchor="middle" '
            f'fill="{self._text_color}" font-size="12" '
            f'transform="rotate(-90 15 {height/2})">{y_label}</text>'
        )
        
        # Draw grid
        for i in range(5):
            y_pos = margin + i * plot_height / 4
            svg.append(
                f'<line x1="{margin}" y1="{y_pos}" x2="{width - margin}" '
                f'y2="{y_pos}" stroke="{self._grid_color}" stroke-dasharray="3,3"/>'
            )
        
        # Draw data points
        for i, backend in enumerate(common_backends):
            x = scale_x(x_data[backend])
            y = scale_y(y_data[backend])
            color = self.CHART_COLORS[i % len(self.CHART_COLORS)]
            
            svg.append(
                f'<circle cx="{x}" cy="{y}" r="8" fill="{color}" '
                f'stroke="white" stroke-width="2" opacity="0.8">'
                f'<title>{backend}\n{x_label}: {x_data[backend]:.2f}\n{y_label}: {y_data[backend]:.2f}</title>'
                f'</circle>'
            )
            
            # Label
            svg.append(
                f'<text x="{x + 10}" y="{y - 10}" fill="{self._text_color}" '
                f'font-size="10">{backend[:8]}</text>'
            )
        
        # Calculate and show correlation
        if len(common_backends) >= 2:
            mean_x = sum(x_values) / len(x_values)
            mean_y = sum(y_values) / len(y_values)
            
            numerator = sum((x_data[b] - mean_x) * (y_data[b] - mean_y) for b in common_backends)
            denom_x = sum((x_data[b] - mean_x) ** 2 for b in common_backends) ** 0.5
            denom_y = sum((y_data[b] - mean_y) ** 2 for b in common_backends) ** 0.5
            
            correlation = numerator / (denom_x * denom_y) if denom_x > 0 and denom_y > 0 else 0
            
            svg.append(
                f'<text x="{width - margin}" y="25" text-anchor="end" '
                f'fill="{self._text_color}" font-size="11">r = {correlation:.3f}</text>'
            )
        
        svg.append('</svg>')
        return '\n'.join(svg)
    
    def generate_line_chart(
        self,
        series_data: dict[str, list[float]],
        x_labels: list[str] | None = None,
        title: str = "Line Chart",
        y_label: str = "Value",
        width: int = 600,
        height: int = 400,
    ) -> str:
        """Generate SVG line chart for trend visualization.
        
        Args:
            series_data: Dict of series_name -> list of values
            x_labels: Labels for X axis points
            title: Chart title
            y_label: Label for Y axis
            width: Chart width
            height: Chart height
            
        Returns:
            SVG string
        """
        if not series_data or not any(series_data.values()):
            return self._empty_svg(title, width, height)
        
        margin = 60
        plot_width = width - 2 * margin
        plot_height = height - 2 * margin - 40
        
        # Get all values for scaling
        all_values = [v for values in series_data.values() for v in values if v is not None]
        if not all_values:
            return self._empty_svg(title, width, height)
        
        y_min = min(all_values)
        y_max = max(all_values)
        y_range = (y_max - y_min) or 1
        y_min -= y_range * 0.1
        y_max += y_range * 0.1
        
        max_points = max(len(v) for v in series_data.values())
        
        def scale_x(idx: int) -> float:
            return margin + (idx / (max_points - 1)) * plot_width if max_points > 1 else margin + plot_width / 2
        
        def scale_y(val: float) -> float:
            return height - margin - 20 - ((val - y_min) / (y_max - y_min)) * plot_height
        
        svg = [
            f'<svg xmlns="http://www.w3.org/2000/svg" width="{width}" height="{height}">',
            f'<rect width="100%" height="100%" fill="{self._bg_color}"/>',
            f'<text x="{width/2}" y="25" text-anchor="middle" font-weight="bold" '
            f'fill="{self._text_color}" font-family="{self.font_family}">{title}</text>',
        ]
        
        # Draw grid
        for i in range(5):
            y_pos = margin + i * plot_height / 4
            y_val = y_max - (i / 4) * (y_max - y_min)
            svg.append(
                f'<line x1="{margin}" y1="{y_pos}" x2="{width - margin}" '
                f'y2="{y_pos}" stroke="{self._grid_color}" stroke-dasharray="3,3"/>'
            )
            svg.append(
                f'<text x="{margin - 5}" y="{y_pos + 4}" text-anchor="end" '
                f'fill="{self._text_color}" font-size="10">{y_val:.1f}</text>'
            )
        
        # Draw lines for each series
        for idx, (series_name, values) in enumerate(series_data.items()):
            color = self.CHART_COLORS[idx % len(self.CHART_COLORS)]
            
            # Build path
            path_points = []
            for i, val in enumerate(values):
                if val is not None:
                    x = scale_x(i)
                    y = scale_y(val)
                    path_points.append(f"{'M' if not path_points else 'L'} {x} {y}")
            
            if path_points:
                svg.append(
                    f'<path d="{" ".join(path_points)}" fill="none" '
                    f'stroke="{color}" stroke-width="2"/>'
                )
                
                # Add data points
                for i, val in enumerate(values):
                    if val is not None:
                        x = scale_x(i)
                        y = scale_y(val)
                        svg.append(
                            f'<circle cx="{x}" cy="{y}" r="4" fill="{color}">'
                            f'<title>{series_name}: {val:.2f}</title></circle>'
                        )
        
        # X-axis labels
        if x_labels:
            for i, label in enumerate(x_labels[:max_points]):
                x = scale_x(i)
                svg.append(
                    f'<text x="{x}" y="{height - margin + 5}" text-anchor="middle" '
                    f'fill="{self._text_color}" font-size="10">{label[:10]}</text>'
                )
        
        # Legend
        legend_y = height - 15
        legend_x = margin
        for idx, series_name in enumerate(series_data.keys()):
            color = self.CHART_COLORS[idx % len(self.CHART_COLORS)]
            svg.append(
                f'<rect x="{legend_x}" y="{legend_y - 8}" width="12" height="12" fill="{color}"/>'
            )
            svg.append(
                f'<text x="{legend_x + 16}" y="{legend_y}" fill="{self._text_color}" '
                f'font-size="10">{series_name}</text>'
            )
            legend_x += len(series_name) * 6 + 30
        
        svg.append('</svg>')
        return '\n'.join(svg)
    
    def generate_histogram(
        self,
        data: list[float],
        bins: int = 10,
        title: str = "Distribution",
        x_label: str = "Value",
        y_label: str = "Frequency",
        width: int = 500,
        height: int = 350,
    ) -> str:
        """Generate SVG histogram for distribution visualization.
        
        Args:
            data: List of values to bin
            bins: Number of bins
            title: Chart title
            x_label: Label for X axis
            y_label: Label for Y axis
            width: Chart width
            height: Chart height
            
        Returns:
            SVG string
        """
        if not data:
            return self._empty_svg(title, width, height)
        
        margin = 60
        plot_width = width - 2 * margin
        plot_height = height - 2 * margin - 20
        
        # Calculate bins
        data_min = min(data)
        data_max = max(data)
        data_range = (data_max - data_min) or 1
        bin_width = data_range / bins
        
        # Count frequencies
        frequencies = [0] * bins
        for val in data:
            bin_idx = min(int((val - data_min) / bin_width), bins - 1)
            frequencies[bin_idx] += 1
        
        max_freq = max(frequencies) or 1
        
        svg = [
            f'<svg xmlns="http://www.w3.org/2000/svg" width="{width}" height="{height}">',
            f'<rect width="100%" height="100%" fill="{self._bg_color}"/>',
            f'<text x="{width/2}" y="25" text-anchor="middle" font-weight="bold" '
            f'fill="{self._text_color}" font-family="{self.font_family}">{title}</text>',
        ]
        
        # Draw axes
        svg.append(
            f'<line x1="{margin}" y1="{height - margin}" x2="{width - margin}" '
            f'y2="{height - margin}" stroke="{self._text_color}"/>'
        )
        svg.append(
            f'<line x1="{margin}" y1="{margin + 20}" x2="{margin}" '
            f'y2="{height - margin}" stroke="{self._text_color}"/>'
        )
        
        # Axis labels
        svg.append(
            f'<text x="{width/2}" y="{height - 10}" text-anchor="middle" '
            f'fill="{self._text_color}" font-size="12">{x_label}</text>'
        )
        svg.append(
            f'<text x="15" y="{height/2}" text-anchor="middle" '
            f'fill="{self._text_color}" font-size="12" '
            f'transform="rotate(-90 15 {height/2})">{y_label}</text>'
        )
        
        # Draw bars
        bar_spacing = 2
        available_width = plot_width - (bins - 1) * bar_spacing
        svg_bar_width = available_width / bins
        
        for i, freq in enumerate(frequencies):
            x = margin + i * (svg_bar_width + bar_spacing)
            bar_height = (freq / max_freq) * plot_height
            y = height - margin - bar_height
            
            color = self.CHART_COLORS[0]
            bin_start = data_min + i * bin_width
            bin_end = bin_start + bin_width
            
            svg.append(
                f'<rect x="{x}" y="{y}" width="{svg_bar_width}" height="{bar_height}" '
                f'fill="{color}" opacity="0.8">'
                f'<title>[{bin_start:.2f}, {bin_end:.2f}): {freq}</title></rect>'
            )
            
            # Frequency label on top
            if freq > 0:
                svg.append(
                    f'<text x="{x + svg_bar_width/2}" y="{y - 5}" text-anchor="middle" '
                    f'fill="{self._text_color}" font-size="9">{freq}</text>'
                )
        
        # X-axis tick labels
        for i in [0, bins // 2, bins]:
            x = margin + i * (svg_bar_width + bar_spacing) - bar_spacing / 2
            val = data_min + i * bin_width
            svg.append(
                f'<text x="{x}" y="{height - margin + 15}" text-anchor="middle" '
                f'fill="{self._text_color}" font-size="10">{val:.1f}</text>'
            )
        
        # Statistics
        mean_val = sum(data) / len(data)
        variance = sum((x - mean_val) ** 2 for x in data) / len(data)
        std_val = variance ** 0.5
        
        svg.append(
            f'<text x="{width - margin}" y="45" text-anchor="end" '
            f'fill="{self._text_color}" font-size="10">={mean_val:.2f}, ={std_val:.2f}</text>'
        )
        
        svg.append('</svg>')
        return '\n'.join(svg)
    
    def generate_box_plot(
        self,
        data_dict: dict[str, list[float]],
        title: str = "Box Plot",
        y_label: str = "Value",
        width: int = 500,
        height: int = 400,
    ) -> str:
        """Generate SVG box plot for statistical comparison.
        
        Args:
            data_dict: Dict of category -> list of values
            title: Chart title
            y_label: Label for Y axis
            width: Chart width
            height: Chart height
            
        Returns:
            SVG string
        """
        if not data_dict or not any(data_dict.values()):
            return self._empty_svg(title, width, height)
        
        margin = 60
        plot_width = width - 2 * margin
        plot_height = height - 2 * margin - 30
        
        # Calculate statistics for each category
        def calc_stats(values: list[float]) -> dict[str, float]:
            sorted_vals = sorted(values)
            n = len(sorted_vals)
            q1_idx = n // 4
            q3_idx = 3 * n // 4
            return {
                "min": sorted_vals[0],
                "q1": sorted_vals[q1_idx],
                "median": sorted_vals[n // 2],
                "q3": sorted_vals[q3_idx],
                "max": sorted_vals[-1],
                "mean": sum(values) / n,
            }
        
        stats = {k: calc_stats(v) for k, v in data_dict.items() if v}
        
        if not stats:
            return self._empty_svg(title, width, height)
        
        # Get global min/max for scaling
        all_mins = [s["min"] for s in stats.values()]
        all_maxs = [s["max"] for s in stats.values()]
        y_min = min(all_mins)
        y_max = max(all_maxs)
        y_range = (y_max - y_min) or 1
        y_min -= y_range * 0.1
        y_max += y_range * 0.1
        
        def scale_y(val: float) -> float:
            return height - margin - 20 - ((val - y_min) / (y_max - y_min)) * plot_height
        
        categories = list(stats.keys())
        n_categories = len(categories)
        box_width = min(60, plot_width / n_categories - 20)
        
        svg = [
            f'<svg xmlns="http://www.w3.org/2000/svg" width="{width}" height="{height}">',
            f'<rect width="100%" height="100%" fill="{self._bg_color}"/>',
            f'<text x="{width/2}" y="25" text-anchor="middle" font-weight="bold" '
            f'fill="{self._text_color}" font-family="{self.font_family}">{title}</text>',
        ]
        
        # Draw grid
        for i in range(5):
            y_pos = margin + 20 + i * plot_height / 4
            y_val = y_max - (i / 4) * (y_max - y_min)
            svg.append(
                f'<line x1="{margin}" y1="{y_pos}" x2="{width - margin}" '
                f'y2="{y_pos}" stroke="{self._grid_color}" stroke-dasharray="3,3"/>'
            )
            svg.append(
                f'<text x="{margin - 5}" y="{y_pos + 4}" text-anchor="end" '
                f'fill="{self._text_color}" font-size="10">{y_val:.1f}</text>'
            )
        
        # Draw box plots
        for idx, category in enumerate(categories):
            s = stats[category]
            color = self.CHART_COLORS[idx % len(self.CHART_COLORS)]
            
            x_center = margin + (idx + 0.5) * (plot_width / n_categories)
            x_left = x_center - box_width / 2
            x_right = x_center + box_width / 2
            
            # Whiskers (min to Q1, Q3 to max)
            svg.append(
                f'<line x1="{x_center}" y1="{scale_y(s["min"])}" x2="{x_center}" '
                f'y2="{scale_y(s["q1"])}" stroke="{color}" stroke-width="2"/>'
            )
            svg.append(
                f'<line x1="{x_center}" y1="{scale_y(s["q3"])}" x2="{x_center}" '
                f'y2="{scale_y(s["max"])}" stroke="{color}" stroke-width="2"/>'
            )
            
            # Whisker caps
            cap_width = box_width / 3
            svg.append(
                f'<line x1="{x_center - cap_width}" y1="{scale_y(s["min"])}" '
                f'x2="{x_center + cap_width}" y2="{scale_y(s["min"])}" stroke="{color}" stroke-width="2"/>'
            )
            svg.append(
                f'<line x1="{x_center - cap_width}" y1="{scale_y(s["max"])}" '
                f'x2="{x_center + cap_width}" y2="{scale_y(s["max"])}" stroke="{color}" stroke-width="2"/>'
            )
            
            # Box (Q1 to Q3)
            box_top = scale_y(s["q3"])
            box_bottom = scale_y(s["q1"])
            svg.append(
                f'<rect x="{x_left}" y="{box_top}" width="{box_width}" '
                f'height="{box_bottom - box_top}" fill="{color}" fill-opacity="0.3" '
                f'stroke="{color}" stroke-width="2"/>'
            )
            
            # Median line
            svg.append(
                f'<line x1="{x_left}" y1="{scale_y(s["median"])}" x2="{x_right}" '
                f'y2="{scale_y(s["median"])}" stroke="{color}" stroke-width="3"/>'
            )
            
            # Mean point
            svg.append(
                f'<circle cx="{x_center}" cy="{scale_y(s["mean"])}" r="4" '
                f'fill="white" stroke="{color}" stroke-width="2"/>'
            )
            
            # Category label
            svg.append(
                f'<text x="{x_center}" y="{height - margin + 15}" text-anchor="middle" '
                f'fill="{self._text_color}" font-size="11">{category[:12]}</text>'
            )
        
        # Y-axis label
        svg.append(
            f'<text x="15" y="{height/2}" text-anchor="middle" '
            f'fill="{self._text_color}" font-size="12" '
            f'transform="rotate(-90 15 {height/2})">{y_label}</text>'
        )
        
        svg.append('</svg>')
        return '\n'.join(svg)
    
    def generate_area_chart(
        self,
        series_data: dict[str, list[float]],
        x_labels: list[str] | None = None,
        title: str = "Area Chart",
        stacked: bool = True,
        width: int = 600,
        height: int = 400,
    ) -> str:
        """Generate SVG area chart for cumulative visualization.
        
        Args:
            series_data: Dict of series_name -> list of values
            x_labels: Labels for X axis points
            title: Chart title
            stacked: Whether to stack areas
            width: Chart width
            height: Chart height
            
        Returns:
            SVG string
        """
        if not series_data or not any(series_data.values()):
            return self._empty_svg(title, width, height)
        
        margin = 60
        plot_width = width - 2 * margin
        plot_height = height - 2 * margin - 40
        
        series_list = list(series_data.items())
        max_points = max(len(v) for v in series_data.values())
        
        # Calculate cumulative values for stacking
        if stacked:
            cumulative = [[0.0] * max_points for _ in range(len(series_list) + 1)]
            for i, (_, values) in enumerate(series_list):
                for j, val in enumerate(values):
                    cumulative[i + 1][j] = cumulative[i][j] + (val or 0)
            y_max = max(cumulative[-1]) if cumulative[-1] else 1
            y_min = 0
        else:
            all_vals = [v for values in series_data.values() for v in values if v is not None]
            y_min = min(all_vals) if all_vals else 0
            y_max = max(all_vals) if all_vals else 1
        
        y_range = (y_max - y_min) or 1
        y_max += y_range * 0.05
        
        def scale_x(idx: int) -> float:
            return margin + (idx / (max_points - 1)) * plot_width if max_points > 1 else margin
        
        def scale_y(val: float) -> float:
            return height - margin - 20 - ((val - y_min) / (y_max - y_min)) * plot_height
        
        svg = [
            f'<svg xmlns="http://www.w3.org/2000/svg" width="{width}" height="{height}">',
            f'<rect width="100%" height="100%" fill="{self._bg_color}"/>',
            f'<text x="{width/2}" y="25" text-anchor="middle" font-weight="bold" '
            f'fill="{self._text_color}" font-family="{self.font_family}">{title}</text>',
        ]
        
        # Draw areas (in reverse order for stacking)
        for i, (series_name, values) in reversed(list(enumerate(series_list))):
            color = self.CHART_COLORS[i % len(self.CHART_COLORS)]
            
            # Build path
            if stacked:
                # Top edge
                path = [f"M {scale_x(0)} {scale_y(cumulative[i + 1][0])}"]
                for j in range(1, len(values)):
                    path.append(f"L {scale_x(j)} {scale_y(cumulative[i + 1][j])}")
                # Bottom edge (reverse)
                for j in range(len(values) - 1, -1, -1):
                    path.append(f"L {scale_x(j)} {scale_y(cumulative[i][j])}")
                path.append("Z")
            else:
                path = [f"M {scale_x(0)} {scale_y(y_min)}"]
                for j, val in enumerate(values):
                    if val is not None:
                        path.append(f"L {scale_x(j)} {scale_y(val)}")
                path.append(f"L {scale_x(len(values) - 1)} {scale_y(y_min)}")
                path.append("Z")
            
            svg.append(
                f'<path d="{" ".join(path)}" fill="{color}" fill-opacity="0.6" '
                f'stroke="{color}" stroke-width="1"/>'
            )
        
        # Legend
        legend_x = margin
        legend_y = height - 15
        for i, series_name in enumerate(series_data.keys()):
            color = self.CHART_COLORS[i % len(self.CHART_COLORS)]
            svg.append(
                f'<rect x="{legend_x}" y="{legend_y - 8}" width="12" height="12" fill="{color}"/>'
            )
            svg.append(
                f'<text x="{legend_x + 16}" y="{legend_y}" fill="{self._text_color}" '
                f'font-size="10">{series_name}</text>'
            )
            legend_x += len(series_name) * 6 + 30
        
        svg.append('</svg>')
        return '\n'.join(svg)
    
    def generate_complete_report(
        self,
        metrics: ComparisonMetrics,
        title: str = "Backend Comparison Report",
        include_charts: list[str] | None = None,
    ) -> VisualizationReport:
        """Generate a complete visualization report with all chart types.
        
        Args:
            metrics: Comparison metrics to visualize
            title: Report title
            include_charts: Specific charts to include (None for all)
            
        Returns:
            VisualizationReport with all generated visualizations
        """
        available_charts = [
            "bar_execution_time", "bar_memory", "scatter_time_memory",
            "heatmap_agreement", "box_plot", "histogram_times", "line_trends"
        ]
        
        charts_to_generate = include_charts or available_charts
        charts: dict[str, str] = {}
        insights: list[str] = []
        
        # Generate requested charts
        if "bar_execution_time" in charts_to_generate and metrics.execution_times:
            viz = ComparisonVisualizer(use_ascii=False)
            charts["bar_execution_time"] = viz._svg_bar_chart(
                metrics.execution_times, "Execution Times (ms)"
            )
            
            fastest = min(metrics.execution_times, key=metrics.execution_times.get)  # type: ignore
            slowest = max(metrics.execution_times, key=metrics.execution_times.get)  # type: ignore
            ratio = metrics.execution_times[slowest] / metrics.execution_times[fastest] if metrics.execution_times[fastest] > 0 else 0
            insights.append(f"Fastest backend: {fastest} ({metrics.execution_times[fastest]:.2f}ms)")
            insights.append(f"Slowest backend: {slowest} ({metrics.execution_times[slowest]:.2f}ms)")
            if ratio > 1:
                insights.append(f"Speed difference: {ratio:.1f}x between fastest and slowest")
        
        if "bar_memory" in charts_to_generate and metrics.memory_peaks:
            viz = ComparisonVisualizer(use_ascii=False)
            charts["bar_memory"] = viz._svg_bar_chart(
                metrics.memory_peaks, "Memory Usage (MB)"
            )
            
            most_efficient = min(metrics.memory_peaks, key=metrics.memory_peaks.get)  # type: ignore
            insights.append(f"Most memory-efficient: {most_efficient} ({metrics.memory_peaks[most_efficient]:.2f}MB)")
        
        if "scatter_time_memory" in charts_to_generate and metrics.execution_times and metrics.memory_peaks:
            charts["scatter_time_memory"] = self.generate_scatter_plot(
                metrics.execution_times,
                metrics.memory_peaks,
                x_label="Execution Time (ms)",
                y_label="Memory Usage (MB)",
                title="Time vs Memory Correlation",
            )
        
        if "heatmap_agreement" in charts_to_generate and metrics.pairwise_agreements:
            viz = ComparisonVisualizer(use_ascii=False)
            charts["heatmap_agreement"] = viz._svg_heatmap(
                metrics.pairwise_agreements, "Result Agreement"
            )
            
            # Find lowest agreement pair
            min_agreement = 1.0
            min_pair = ("", "")
            for b1, agreements in metrics.pairwise_agreements.items():
                for b2, agreement in agreements.items():
                    if b1 != b2 and agreement < min_agreement:
                        min_agreement = agreement
                        min_pair = (b1, b2)
            if min_pair[0]:
                insights.append(f"Lowest agreement: {min_pair[0]} vs {min_pair[1]} ({min_agreement*100:.1f}%)")
        
        if "histogram_times" in charts_to_generate and metrics.execution_times:
            time_values = list(metrics.execution_times.values())
            if len(time_values) >= 3:
                charts["histogram_times"] = self.generate_histogram(
                    time_values,
                    bins=min(len(time_values), 10),
                    title="Execution Time Distribution",
                    x_label="Time (ms)",
                )
        
        if "box_plot" in charts_to_generate and metrics.execution_times:
            # Create box plot data from single measurements (would need multiple runs for real box plots)
            box_data = {k: [v] for k, v in metrics.execution_times.items()}
            charts["box_plot"] = self.generate_box_plot(
                box_data,
                title="Execution Time Statistics",
                y_label="Time (ms)",
            )
        
        # Calculate summary stats
        summary_stats = {
            "total_backends": len(metrics.execution_times),
            "avg_execution_time": sum(metrics.execution_times.values()) / len(metrics.execution_times) if metrics.execution_times else 0,
            "avg_memory_usage": sum(metrics.memory_peaks.values()) / len(metrics.memory_peaks) if metrics.memory_peaks else 0,
            "fastest_backend": metrics.fastest_backend,
            "overall_agreement": metrics.result_agreement,
        }
        
        # Generate HTML report
        html_report = self._generate_html_report(title, charts, insights, summary_stats)
        
        return VisualizationReport(
            title=title,
            generated_at=datetime.now(),
            charts=charts,
            html_report=html_report,
            insights=insights,
            summary_stats=summary_stats,
        )
    
    def _generate_html_report(
        self,
        title: str,
        charts: dict[str, str],
        insights: list[str],
        summary_stats: dict[str, Any],
    ) -> str:
        """Generate complete HTML report with all charts."""
        charts_html = ""
        for chart_name, svg_content in charts.items():
            display_name = chart_name.replace("_", " ").title()
            charts_html += f'''
            <div class="chart-section">
                <h3>{display_name}</h3>
                <div class="chart-container">{svg_content}</div>
            </div>
            '''
        
        insights_html = "".join(f"<li>{insight}</li>" for insight in insights)
        
        return f"""<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{title}</title>
    <style>
        body {{
            font-family: {self.font_family};
            background: {self._bg_color};
            color: {self._text_color};
            margin: 0;
            padding: 20px;
            line-height: 1.6;
        }}
        .container {{
            max-width: 1200px;
            margin: 0 auto;
        }}
        h1 {{
            text-align: center;
            border-bottom: 2px solid #3498db;
            padding-bottom: 10px;
        }}
        .summary {{
            background: {'#f8f9fa' if self.theme == 'light' else '#2d2d4a'};
            padding: 20px;
            border-radius: 8px;
            margin: 20px 0;
        }}
        .summary h2 {{
            margin-top: 0;
        }}
        .summary-grid {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
        }}
        .stat-card {{
            background: {'white' if self.theme == 'light' else '#1a1a2e'};
            padding: 15px;
            border-radius: 8px;
            text-align: center;
        }}
        .stat-value {{
            font-size: 24px;
            font-weight: bold;
            color: #3498db;
        }}
        .stat-label {{
            font-size: 12px;
            opacity: 0.8;
        }}
        .insights {{
            background: {'#e8f4f8' if self.theme == 'light' else '#1e3a4a'};
            padding: 20px;
            border-radius: 8px;
            margin: 20px 0;
        }}
        .insights ul {{
            margin: 0;
            padding-left: 20px;
        }}
        .charts-grid {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(400px, 1fr));
            gap: 20px;
            margin-top: 30px;
        }}
        .chart-section {{
            background: {'white' if self.theme == 'light' else '#2d2d4a'};
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }}
        .chart-section h3 {{
            margin-top: 0;
            border-bottom: 1px solid {'#eee' if self.theme == 'light' else '#444'};
            padding-bottom: 10px;
        }}
        .chart-container {{
            display: flex;
            justify-content: center;
            overflow-x: auto;
        }}
        .footer {{
            text-align: center;
            margin-top: 30px;
            padding-top: 20px;
            border-top: 1px solid {'#ddd' if self.theme == 'light' else '#444'};
            font-size: 12px;
            opacity: 0.7;
        }}
        @media print {{
            body {{ background: white; color: black; }}
            .chart-section {{ break-inside: avoid; }}
        }}
    </style>
</head>
<body>
    <div class="container">
        <h1>{title}</h1>
        
        <div class="summary">
            <h2> Summary Statistics</h2>
            <div class="summary-grid">
                <div class="stat-card">
                    <div class="stat-value">{summary_stats.get('total_backends', 0)}</div>
                    <div class="stat-label">Backends Compared</div>
                </div>
                <div class="stat-card">
                    <div class="stat-value">{summary_stats.get('avg_execution_time', 0):.2f}ms</div>
                    <div class="stat-label">Avg Execution Time</div>
                </div>
                <div class="stat-card">
                    <div class="stat-value">{summary_stats.get('avg_memory_usage', 0):.2f}MB</div>
                    <div class="stat-label">Avg Memory Usage</div>
                </div>
                <div class="stat-card">
                    <div class="stat-value">{summary_stats.get('fastest_backend', 'N/A')}</div>
                    <div class="stat-label">Fastest Backend</div>
                </div>
                <div class="stat-card">
                    <div class="stat-value">{summary_stats.get('overall_agreement', 0)*100:.1f}%</div>
                    <div class="stat-label">Overall Agreement</div>
                </div>
            </div>
        </div>
        
        <div class="insights">
            <h2> Key Insights</h2>
            <ul>
                {insights_html}
            </ul>
        </div>
        
        <div class="charts-grid">
            {charts_html}
        </div>
        
        <div class="footer">
            Generated by Proxima Visualization Engine  {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
        </div>
    </div>
</body>
</html>"""
    
    def export_chart(
        self,
        svg_content: str,
        output_path: Path,
        options: ChartExportOptions | None = None,
    ) -> bool:
        """Export chart to file.
        
        Args:
            svg_content: SVG string content
            output_path: Output file path
            options: Export options
            
        Returns:
            True if successful
        """
        options = options or ChartExportOptions()
        
        try:
            output_path = Path(output_path)
            output_path.parent.mkdir(parents=True, exist_ok=True)
            
            if options.format == "svg":
                output_path.write_text(svg_content, encoding="utf-8")
            elif options.format == "html":
                html = f"""<!DOCTYPE html>
<html>
<head><title>Chart Export</title></head>
<body style="margin:0; display:flex; justify-content:center; align-items:center; min-height:100vh;">
{svg_content}
</body>
</html>"""
                output_path.write_text(html, encoding="utf-8")
            else:
                # For other formats, save as SVG with note
                output_path.with_suffix(".svg").write_text(svg_content, encoding="utf-8")
            
            return True
        except Exception:
            return False
    
    def _empty_svg(self, title: str, width: int, height: int) -> str:
        """Generate empty SVG placeholder."""
        return f'''<svg xmlns="http://www.w3.org/2000/svg" width="{width}" height="{height}">
            <rect width="100%" height="100%" fill="{self._bg_color}"/>
            <text x="{width/2}" y="{height/2}" text-anchor="middle" 
                  fill="{self._text_color}" font-size="14">{title}: No data available</text>
        </svg>'''
